{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial will show how to use `mhar` for sampling polytopes. It is focused on executing parallel MCMC walks over a polytope in GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting let's check if you have an avaialble gpu device or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu').type\n",
    "print('Device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to decide the data-type `dtype` we are going to use. Depending on your necessities you can choose it, we recomend to use `64` bits for non-fully dimentional polytopes in order to maintain numerical inestability of the projections. Otherwiise the precision depends on the dimension of your polytope and speed you want.  \n",
    "  \n",
    "As of now `16` bit precision is only available for `gpu` and not `cpu`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will choose 64-bits\n",
    "dtype = torch.float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Canonical Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The polytope in question must be presented in matrix canonical representation (as opposed to vertex). `mhar` assumes that the matrix has no repeated or redundant restrictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully dimensional Polytopes  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> $A^IX \\leq b^I$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For fully dimensional polytopes we need to use the class `Polytope` in the `mhar.polytope` module. The restrictions must be passed as pytorch tensors.  \n",
    "  \n",
    "We will sample the unit hypercube that is defined as:  \n",
    "> $n-hypercube = \\{x \\in R^n || x \\in [-1,1]^n \\} $  \n",
    "\n",
    "Which we can represent in matrix restrictions:  \n",
    "$ Ix \\leq 1$  \n",
    "$ -Ix \\leq 1$  \n",
    "Where $I$ is the identity matrix of dimension $n \\times n$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use this restrictions to define the polytope as:  \n",
    "$A^Ix = [I | -I]x \\leq 1 = b^I$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition-Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create the tensors to represent the restrictions that define the polytope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inequality Matrix A^I \n",
      " tensor([[ 1.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.],\n",
      "        [ 0.,  0.,  1.],\n",
      "        [-1., -0., -0.],\n",
      "        [-0., -1., -0.],\n",
      "        [-0., -0., -1.]]) \n",
      "\n",
      "Inequality Vector b^I \n",
      " tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]])\n"
     ]
    }
   ],
   "source": [
    "n = 3 # Dimension\n",
    "dtype = torch.float32 # Precision \n",
    "A_I = torch.cat((torch.eye(n), torch.eye(n) * -1.0), dim=0).to(dtype) # Inequality Matrix\n",
    "b_I = torch.ones(2 * n, dtype=dtype).view(-1, 1)  # Inequality restriction vector      \n",
    "print(f'Inequality Matrix A^I \\n {A_I} \\n')\n",
    "print(f'Inequality Vector b^I \\n {b_I}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets create a `Polytope` object to represent the polytope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/uumami/sonder.art/mhar/mhar/polytope.py:45: UserWarning:\n",
      "  The object will not create a copy of the tensors, so modifications will be reflected in the object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mhar.polytope import Polytope\n",
    "hypercube = Polytope(A_I, # Inequality Restriction Matrix \n",
    "                     b_I,  # Inequality Vector\n",
    "                     dtype, # torch dtype\n",
    "                     device, # device used cpu or cuda\n",
    "                     copy=False # bool for creating a copy of the restrictions\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Numeric Precision (dtype) torch.float32\n",
       "Device: cuda\n",
       "A_in: torch.Size([6, 3]) \n",
       "b_in: torch.Size([6, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypercube"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting Inner Point(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to start the algorithm we need at least one inner point $x_0$. If you know your inner point you can supply it to the algorithm, `mhar` also contains functions to compute one inner point using the [chebyshev center](https://en.wikipedia.org/wiki/Chebyshev_center) which finds the center of the smallest ball inside the polytope.\n",
    "\n",
    " `from mhar.inner_point import ChebyshevCenter`. The solver is in numpy so precision must be specified as `numpy.dtype`. It uses `linprog` from `scipy.optimize`. You can see the documentation [here](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.linprog.html). \n",
    "  \n",
    "It could also be the last points produced by a previous walk/run of the `mhar` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mhar.inner_point import ChebyshevCenter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Simplex Status for the Chebyshev Center\n",
      " Optimization proceeding nominally.\n"
     ]
    }
   ],
   "source": [
    "x0 = ChebyshevCenter(polytope=hypercube, # Polytope Object\n",
    "                    lb=None,  # Lowerbound (lb <= x ), if unknown leave it as None \n",
    "                    ub=None,  # Upperbound ( x <= up), if unknown leave it as None \n",
    "                    tolerance=1e-4, # Tolerance for equality restrictions (A_eqx = b_eq)\n",
    "                    device='cuda', # device used cpu or cuda\n",
    "                    solver_precision=np.float32 # numpy dtype\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.],\n",
       "        [-0.],\n",
       "        [-0.]], device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to manually input the inner points then it is enough to use a torch tensor of size $n \\times l$. Where $l$ is ne number of inner points you want to supply. Just write them in column notation.  \n",
    "  \n",
    "We are going to manually add an other starting point to the one calcualted by the `chebyshev center` to show its functionality later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0000, 0.5000],\n",
       "        [-0.0000, 0.5000],\n",
       "        [-0.0000, 0.5000]], device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0 = torch.cat([x0, \n",
    "            torch.tensor([[.5], [.5], [.5]]).to(device).to(dtype)\n",
    "             ], dim=1)\n",
    "x0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can proceed to sample the `polytope`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Walk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to sample the polytope starting from the inner points we supply using the method `walk.walk`. It has the next arguments:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ `polytope` is an object of the type `Polytope` or `NFDPolytope` that defines it.\n",
    "+ `X0` a tensor containing the inner points to start the walks from.\n",
    "+ `z` determines the number of simoultaneous `walks`. If the number of initial points supplied are less than `z`  ($ncols($ `x0` $) < $ `z`) then some points will be reused as starting points.  \n",
    "+ `T` is the number of uncorrelated iterations you want. The number of total uncorrelated points produced by the algorithm is `z` $\\times$ `T`, since `z` points are sampled at each iteration.  \n",
    "+ `thinning` determines the number of points that we need to burn between iterations in order to get uncorrelated points. The suggested factor should be in the order of $O(n^3)$.\n",
    "+ `warm` determines a thinning for warming the walks only at the beggining, after the this war the walks resumes as normal. It is used if you want to lose the dependency from the starting points.\n",
    "+ `device` device where the tenros live `cpu` or `cuda`\n",
    "+ `seed` for reproducibility\n",
    "+ `verbosity` for printing what is going on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum number allowed -3.4028234663852886e+38\n",
      "Maximum number allowed 3.4028234663852886e+38\n",
      "Eps:  1.1920928955078125e-07\n",
      "Values close to zero will be converted to 3eps or -3eps: 3.5762786865234375e-07\n",
      "n:  3   mI: 6   mE: None   z: 100\n",
      "% of burned samples |██████████████████████████████| 100.0%\n",
      "% of iid samples |██████████████████████████████| 100.0%\n"
     ]
    }
   ],
   "source": [
    "from mhar.walk import walk\n",
    "X = walk(polytope=hypercube,\n",
    "        X0 = x0,  \n",
    "        z=100, \n",
    "        T=1, \n",
    "        warm=0,\n",
    "        thinning=3**3, \n",
    "        device= None, \n",
    "        seed=None,\n",
    "        verbosity=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`walk` produces `T` $\\times$ `z` uncorrelated points. It returns a vector of dimension `T` $\\times$ `z` $\\times$ `n`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1346,  0.1896,  0.8120,  0.2621, -0.1261, -0.6093, -0.8195,\n",
       "           0.4585, -0.6270,  0.2019,  0.2617, -0.2022, -0.6854, -0.8556,\n",
       "          -0.2954, -0.4730, -0.8601, -0.3819, -0.9203, -0.7145,  0.2585,\n",
       "           0.3860, -0.3928, -0.0756,  0.7155, -0.0701, -0.6295, -0.9855,\n",
       "          -0.4843,  0.6900, -0.1447, -0.7108, -0.5022, -0.9553,  0.3655,\n",
       "          -0.3814,  0.5704,  0.6801,  0.2533,  0.9957,  0.0294,  0.5533,\n",
       "           0.1137, -0.9384, -0.3501,  0.0382, -0.1064,  0.8821,  0.9229,\n",
       "          -0.5929, -0.1313,  0.8912, -0.5393, -0.2716, -0.4064, -0.6508,\n",
       "          -0.2260,  0.7822,  0.1814,  0.1944, -0.3762, -0.5079,  0.1859,\n",
       "          -0.0317,  0.0774, -0.7498, -0.6107, -0.9015,  0.5549,  0.9456,\n",
       "           0.7679, -0.4838,  0.6325, -0.5565,  0.5174,  0.4736, -0.2022,\n",
       "          -0.4906, -0.9142, -0.2539, -0.7834, -0.9992,  0.8694,  0.5327,\n",
       "           0.0498, -0.0449, -0.4333, -0.1756, -0.9705, -0.0613,  0.4504,\n",
       "           0.1786,  0.8194,  0.9220, -0.2853, -0.9626,  0.8610, -0.2473,\n",
       "           0.6959,  0.9929],\n",
       "         [-0.2811,  0.7823,  0.3258,  0.1882,  0.6521,  0.9662,  0.9538,\n",
       "          -0.6207,  0.3506, -0.1506, -0.7610, -0.4237,  0.4964, -0.9281,\n",
       "          -0.1082, -0.3890, -0.0908, -0.1928,  0.4407,  0.7635, -0.0636,\n",
       "           0.5587,  0.3643, -0.7028, -0.2802, -0.9121, -0.9970, -0.2032,\n",
       "           0.3284, -0.4812,  0.9609,  0.7314, -0.3476, -0.7837, -0.7843,\n",
       "          -0.4753, -0.0046,  0.1882,  0.3255,  0.1868,  0.4025,  0.4896,\n",
       "          -0.7197, -0.7012, -0.3682, -0.0018,  0.4700, -0.9776,  0.3331,\n",
       "          -0.6803, -0.9414,  0.5299,  0.7434, -0.5151,  0.4549, -0.9198,\n",
       "           0.3182, -0.8480, -0.3787,  0.7678, -0.6883, -0.0720,  0.6357,\n",
       "          -0.9480, -0.6667, -0.7260, -0.9163, -0.6217,  0.1803,  0.8281,\n",
       "           0.1085,  0.1036, -0.1528, -0.6564, -0.1672, -0.8180, -0.3201,\n",
       "           0.0829,  0.9518, -0.4597, -0.1895,  0.5383,  0.4491,  0.3004,\n",
       "           0.7061, -0.7125,  0.7620,  0.4825,  0.6123,  0.8469, -0.2125,\n",
       "          -0.7799,  0.2524, -0.5815,  0.1629, -0.6301, -0.2453,  0.6329,\n",
       "           0.8825, -0.9193],\n",
       "         [-0.9438,  0.5869,  0.4422, -0.0073,  0.4678, -0.7397,  0.8975,\n",
       "          -0.9806, -0.7742, -0.9265,  0.2176,  0.9492, -0.3944,  0.4756,\n",
       "          -0.8823,  0.2533, -0.0426,  0.1134,  0.1315,  0.1589,  0.6258,\n",
       "           0.9466,  0.6489,  0.7711, -0.8410, -0.0462,  0.9653,  0.1752,\n",
       "           0.0772,  0.9146,  0.2100,  0.2090,  0.1589, -0.8005,  0.1775,\n",
       "          -0.9659,  0.6359,  0.1348, -0.1756, -0.8340, -0.4709, -0.5705,\n",
       "           0.6959,  0.3317,  0.1630, -0.3927, -0.2396, -0.3620,  0.1677,\n",
       "           0.8126, -0.3664,  0.2817, -0.7107,  0.5458, -0.9493,  0.1481,\n",
       "          -0.5987,  0.1597, -0.2120, -0.0451, -0.7265, -0.0624, -0.9850,\n",
       "          -0.8002, -0.3036, -0.8584, -0.9586, -0.9752, -0.4340,  0.0158,\n",
       "           0.6479, -0.6066, -0.1113,  0.0625, -0.3685,  0.7402,  0.5483,\n",
       "           0.0695, -0.9330,  0.2421, -0.3996, -0.2566,  0.7821, -0.9107,\n",
       "           0.6169, -0.6838,  0.8823,  0.2662, -0.4452, -0.9421,  0.9419,\n",
       "           0.5721,  0.0020, -0.7972, -0.0144,  0.1817, -0.6556,  0.1853,\n",
       "           0.8581, -0.0904]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To sumamrize the steps taken we can use the `polytope_examples` for creating a `Hypercube`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/uumami/sonder.art/mhar/mhar/polytope.py:45: UserWarning:\n",
      "  The object will not create a copy of the tensors, so modifications will be reflected in the object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mhar.polytope_examples import Hypercube\n",
    "\n",
    "# Create a polytope (Hypercube)\n",
    "hypercube = Hypercube(10,\n",
    "                      dtype=torch.float32,\n",
    "                      device='cuda'\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define/Find inner points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Simplex Status for the Chebyshev Center\n",
      " Optimization proceeding nominally.\n"
     ]
    }
   ],
   "source": [
    "x0 = ChebyshevCenter(polytope=hypercube, \n",
    "                    lb=None, \n",
    "                    ub=None, \n",
    "                    tolerance=1e-4,\n",
    "                    device='cuda',\n",
    "                    solver_precision=np.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum number allowed -3.4028234663852886e+38\n",
      "Maximum number allowed 3.4028234663852886e+38\n",
      "Eps:  1.1920928955078125e-07\n",
      "Values close to zero will be converted to 3eps or -3eps: 3.5762786865234375e-07\n",
      "n:  10   mI: 20   mE: None   z: 100\n",
      "% of burned samples |██████████████████████████████| 100.0%\n",
      "% of iid samples |██████████████████████████████| 100.0%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-3.8327e-01,  7.8069e-02,  2.9651e-01,  6.9654e-01, -9.8001e-01,\n",
       "          -7.6946e-01,  9.5175e-01, -3.8984e-01, -2.3625e-01,  3.4791e-02,\n",
       "           9.0714e-01,  1.2673e-01,  6.5063e-01,  3.3621e-01, -4.3635e-01,\n",
       "          -5.0896e-01, -9.7254e-01, -5.6308e-01,  1.9761e-01,  3.7554e-01,\n",
       "           6.2283e-01, -6.3949e-01, -1.2451e-02, -6.9506e-01, -6.0431e-01,\n",
       "          -4.7805e-01, -5.9062e-01,  3.3656e-01,  3.5997e-01, -7.2770e-01,\n",
       "           7.9037e-01, -6.7223e-01, -2.8605e-01, -5.9226e-01,  4.7954e-01,\n",
       "           7.4920e-02,  7.0809e-01, -3.3553e-01,  9.6565e-01, -2.4111e-01,\n",
       "           2.0464e-01,  4.4271e-01,  3.8480e-01, -1.0596e-03,  3.6338e-01,\n",
       "          -9.3107e-01,  5.2171e-01, -7.4777e-01, -9.5047e-02, -6.4247e-01,\n",
       "          -2.5327e-02, -1.5993e-01,  6.2042e-01, -3.8698e-01,  3.5689e-01,\n",
       "          -5.2772e-01, -8.7221e-01, -4.0191e-01, -5.3989e-01,  8.4517e-01,\n",
       "           5.2379e-01, -6.2028e-01,  7.3326e-02, -7.7204e-01, -4.3243e-01,\n",
       "          -9.5900e-01,  1.3927e-01, -3.4701e-01, -6.2617e-01,  2.2573e-01,\n",
       "          -9.9449e-01, -9.8055e-01,  3.5983e-01, -2.2122e-01, -4.7873e-01,\n",
       "           8.6630e-01,  5.7154e-01, -1.7567e-01,  8.7809e-01,  1.3939e-01,\n",
       "          -3.0077e-01, -2.5320e-01,  7.6909e-01,  9.0643e-01, -5.7199e-01,\n",
       "          -9.4331e-01, -4.3507e-01,  3.9268e-01,  4.2593e-02, -9.5721e-01,\n",
       "          -2.7239e-01, -5.7193e-01, -7.7561e-01,  5.2424e-01, -3.3273e-01,\n",
       "           4.7645e-01,  7.9793e-01,  6.8381e-01, -2.2922e-01,  1.9818e-01],\n",
       "         [ 5.8924e-01,  4.4006e-01, -1.2454e-01, -6.1653e-01, -8.2044e-01,\n",
       "           5.0092e-01, -4.9186e-01,  3.7525e-01,  5.5419e-01, -6.1689e-01,\n",
       "           7.7791e-01,  6.3836e-01,  9.0519e-01, -1.3609e-01,  6.0843e-01,\n",
       "           8.1185e-01, -3.2591e-01,  7.9253e-01, -7.4439e-01,  6.8469e-01,\n",
       "           9.1378e-01,  9.8280e-01,  7.1928e-01, -9.4081e-01,  1.9410e-01,\n",
       "          -1.1952e-01,  3.2861e-01, -8.8787e-01, -8.9373e-01, -8.4826e-01,\n",
       "           6.3443e-01, -4.0640e-01,  6.4031e-02,  4.4047e-02, -8.9053e-02,\n",
       "          -7.0800e-01,  2.4085e-01,  6.6288e-01, -7.0049e-01,  8.2513e-01,\n",
       "           3.5290e-01,  6.4375e-01,  3.8404e-01,  3.0183e-01,  6.5208e-01,\n",
       "          -7.4302e-01, -9.2352e-01,  5.8262e-01, -2.1288e-01, -4.5132e-01,\n",
       "          -1.0712e-01, -9.6062e-01,  1.8931e-01, -9.0335e-01,  3.9141e-01,\n",
       "          -1.3346e-02,  3.9639e-02, -8.9020e-01,  8.0701e-01,  9.9940e-01,\n",
       "           3.6927e-01, -7.1594e-01, -6.7843e-01,  2.6448e-01, -8.2808e-01,\n",
       "          -2.9121e-01, -5.6895e-01, -5.6116e-02,  3.9635e-01, -2.4406e-01,\n",
       "          -1.5301e-01,  2.9653e-01,  1.9789e-01,  6.9877e-03,  8.1104e-01,\n",
       "          -5.9562e-01, -5.6026e-01,  1.8886e-01,  6.4847e-01,  6.3157e-01,\n",
       "          -8.0962e-01, -3.0029e-01, -3.9985e-01,  2.7034e-01,  7.9322e-02,\n",
       "           2.8147e-01,  7.9183e-01,  7.6771e-01, -7.2012e-01,  4.0805e-01,\n",
       "           6.6703e-01, -9.6850e-01, -1.0882e-01, -1.5547e-01, -3.9726e-01,\n",
       "          -8.1700e-01, -6.4632e-01,  1.8809e-01,  1.6914e-01,  6.1549e-01],\n",
       "         [ 9.9088e-01, -6.6083e-02,  5.8655e-01, -9.9910e-01, -2.4165e-01,\n",
       "          -1.0577e-01, -1.0137e-01,  5.1084e-01,  6.5918e-01, -7.2042e-01,\n",
       "           5.0206e-01, -8.0938e-01, -2.2088e-01, -6.6514e-01,  7.3738e-01,\n",
       "           7.6759e-01, -5.0645e-01, -8.8226e-01,  7.2517e-01,  5.1149e-01,\n",
       "          -7.5878e-01, -2.3206e-02, -9.0562e-01,  2.9245e-01,  5.2743e-01,\n",
       "           9.8978e-01,  6.2080e-01, -6.5277e-01, -4.6134e-01,  8.3459e-02,\n",
       "           4.6184e-01,  1.9695e-01, -2.5713e-01, -1.2280e-02, -5.7240e-02,\n",
       "          -9.4594e-01, -9.8484e-01, -5.2409e-01, -3.8784e-01, -1.1889e-01,\n",
       "          -1.5224e-01,  4.2053e-01, -3.4651e-01, -9.3598e-01, -8.8367e-02,\n",
       "           2.4716e-02, -3.3743e-02,  5.8477e-01, -8.4276e-02,  6.0872e-01,\n",
       "          -7.1033e-01, -6.8853e-01,  7.8002e-01,  9.7775e-02,  5.7438e-01,\n",
       "           6.5246e-02,  9.6351e-01,  5.1909e-01, -9.8356e-01,  8.0237e-01,\n",
       "           4.8092e-01,  4.1042e-01, -1.9292e-01,  5.7682e-01, -5.1712e-01,\n",
       "           3.1930e-01,  5.5679e-02,  6.0419e-01, -4.9618e-01, -3.8974e-01,\n",
       "          -2.9984e-01, -8.2220e-01,  2.9641e-01,  7.9682e-01, -6.4698e-01,\n",
       "          -1.2807e-01,  3.4118e-01, -2.2346e-01,  4.8971e-01, -7.8829e-01,\n",
       "           4.7061e-02,  2.1057e-01, -2.5668e-01,  5.0173e-01, -4.0291e-02,\n",
       "           9.3952e-01, -9.8251e-01,  8.9629e-01,  9.2095e-01, -1.0432e-01,\n",
       "           4.2152e-01,  9.2345e-01,  4.7128e-01,  3.8983e-02,  3.1967e-01,\n",
       "          -1.5074e-02, -3.3511e-01,  2.6453e-01, -8.7885e-01, -2.2789e-01],\n",
       "         [ 4.5208e-01,  1.4018e-01,  5.4559e-01,  5.0096e-01,  3.8467e-01,\n",
       "           7.6218e-01, -9.1356e-01,  9.3258e-01, -1.1362e-01,  9.5726e-01,\n",
       "          -3.2735e-01, -4.5493e-01,  8.9167e-01, -1.6736e-01, -4.6566e-01,\n",
       "           4.6590e-01,  9.7291e-01, -6.6883e-01,  1.8236e-01, -6.5317e-01,\n",
       "           7.0813e-01,  3.3953e-01, -6.6701e-01, -1.3769e-01,  2.1175e-01,\n",
       "          -3.8505e-01, -1.9828e-01,  1.5913e-01, -2.9242e-03,  2.2723e-01,\n",
       "           6.7104e-01, -3.0872e-01, -6.8856e-01,  4.9426e-01, -1.6310e-01,\n",
       "          -8.7184e-01, -8.0671e-01,  5.1659e-01,  1.6381e-01,  3.8452e-01,\n",
       "          -4.6838e-01,  1.2962e-01,  8.8300e-01, -2.6466e-01,  3.1197e-01,\n",
       "          -2.7521e-01,  9.4399e-01, -7.8130e-01,  4.3484e-01,  1.3381e-01,\n",
       "          -5.8684e-01, -7.3642e-01, -3.4039e-01, -7.5530e-01,  8.4271e-01,\n",
       "          -5.0079e-02, -9.7355e-01, -5.4745e-01,  1.1802e-01,  4.6515e-01,\n",
       "           9.3273e-01,  2.5507e-01, -4.5865e-01,  7.3102e-01, -2.5944e-01,\n",
       "           2.3994e-01, -2.5593e-01,  1.1020e-01, -1.4556e-01, -4.6975e-01,\n",
       "          -2.3690e-01,  7.5701e-01,  2.7793e-01, -1.3798e-01, -1.9901e-01,\n",
       "           1.6401e-02,  1.8611e-02,  8.5582e-01, -1.2693e-02, -2.5701e-01,\n",
       "           1.8362e-01,  6.2751e-01, -2.4484e-01,  4.7770e-01,  5.3110e-01,\n",
       "          -1.7457e-01, -7.8095e-01,  8.0351e-01,  4.5764e-02,  3.6209e-02,\n",
       "           1.7541e-01,  1.6617e-01,  7.4761e-01, -8.8258e-01,  2.0417e-01,\n",
       "          -8.2428e-01, -8.7700e-01,  9.5108e-01, -8.1682e-01, -3.1739e-01],\n",
       "         [-1.4508e-02,  5.4910e-01,  5.5915e-01, -8.1735e-01, -8.5881e-01,\n",
       "          -8.0873e-01,  5.8834e-01, -2.8610e-01, -4.2496e-01,  2.7666e-01,\n",
       "           4.6160e-01, -9.1880e-01,  7.5906e-02,  2.8089e-01, -8.8632e-01,\n",
       "          -6.8430e-03,  4.1261e-01, -4.1374e-01, -9.0808e-01,  8.1330e-01,\n",
       "          -3.1951e-01,  8.4421e-01, -2.8660e-01,  7.1102e-01,  8.2436e-02,\n",
       "           1.9957e-01, -7.4491e-01, -9.2732e-01,  8.4900e-01,  2.0558e-01,\n",
       "           8.1877e-01, -2.7528e-01,  2.2502e-01, -1.8636e-03, -1.4710e-02,\n",
       "           6.2849e-01, -1.3615e-01,  3.0727e-01,  3.3098e-01, -2.8052e-01,\n",
       "           8.3493e-01, -9.9923e-01,  8.5341e-01, -7.2669e-01,  5.2624e-01,\n",
       "          -9.3051e-01, -1.4567e-01, -6.3048e-01,  1.5715e-01,  7.0740e-01,\n",
       "           4.8589e-01,  2.9422e-01,  2.0917e-01, -4.9673e-01, -3.6601e-02,\n",
       "           4.9035e-01,  9.0368e-01, -9.0394e-01, -4.1720e-01,  8.0733e-02,\n",
       "           2.2413e-01,  9.3336e-01, -5.1913e-01, -7.6627e-01, -1.9852e-01,\n",
       "          -3.6870e-01, -2.0933e-01, -5.4425e-01,  9.7410e-01,  5.1964e-02,\n",
       "           5.8334e-03,  1.7052e-01, -5.8039e-01,  9.2465e-01, -5.8031e-01,\n",
       "           8.0342e-01, -2.9483e-01, -9.9537e-01,  7.9920e-01, -8.7912e-01,\n",
       "          -5.3839e-01,  8.3277e-01, -3.9591e-01, -9.6479e-01,  9.7826e-01,\n",
       "           1.0108e-01, -3.8486e-01,  7.1464e-01,  7.7453e-01, -1.9147e-01,\n",
       "           3.4499e-01, -1.8815e-01,  1.2674e-01, -3.5575e-01, -7.1273e-01,\n",
       "           1.0664e-01,  5.8791e-01, -3.9316e-01, -5.2373e-01,  5.3612e-01],\n",
       "         [-3.0710e-01, -7.4929e-01, -2.8093e-01, -7.4234e-01,  9.5312e-01,\n",
       "           3.9336e-01,  5.3695e-01,  2.9887e-01,  4.6058e-01,  2.2908e-01,\n",
       "          -5.0698e-01,  9.5565e-01, -9.7928e-01, -6.0857e-01,  5.6201e-01,\n",
       "          -1.7352e-01,  6.8693e-01, -9.3904e-01, -2.1399e-01,  2.7967e-02,\n",
       "          -2.0600e-01,  6.7331e-01,  4.9256e-01,  4.3192e-01, -5.2695e-01,\n",
       "           1.5888e-01,  5.3948e-01, -4.5042e-01, -6.3632e-01, -5.4632e-01,\n",
       "           1.1436e-01, -8.6147e-01,  4.8195e-01,  5.9065e-01, -8.0250e-01,\n",
       "          -6.9360e-01, -3.4959e-01,  3.4300e-01, -8.2958e-01,  1.9462e-01,\n",
       "          -6.9993e-01,  3.0429e-01, -6.8130e-01,  3.8511e-01,  3.5358e-02,\n",
       "           2.8590e-01, -7.5230e-01,  7.3434e-01, -8.3914e-01, -5.2789e-01,\n",
       "          -1.9962e-02, -9.9693e-01,  7.1445e-01,  6.0858e-01, -3.1681e-01,\n",
       "          -7.6498e-01,  4.6854e-01,  2.8101e-01,  6.5559e-01,  8.5469e-01,\n",
       "          -7.0735e-01, -8.9954e-01, -2.9658e-01,  7.4515e-01,  2.8176e-01,\n",
       "           2.6721e-01, -9.8260e-01,  6.9311e-01, -7.6597e-02, -9.9507e-01,\n",
       "          -6.7873e-01,  8.4460e-01,  3.9934e-01, -9.4159e-01, -6.9285e-01,\n",
       "           6.1625e-01, -9.5819e-01,  4.0549e-01,  8.8348e-01, -1.0361e-02,\n",
       "           7.0176e-01,  8.2913e-01, -7.8097e-01, -3.9647e-01, -2.3138e-01,\n",
       "          -2.5184e-01, -1.0440e-01,  9.1550e-01,  2.7608e-01,  6.9223e-01,\n",
       "          -5.7482e-01, -1.3896e-01, -8.0302e-01, -3.4696e-01,  1.3735e-01,\n",
       "           4.6799e-01, -8.8568e-01,  7.3774e-01,  4.1662e-02, -4.4767e-01],\n",
       "         [ 7.6797e-01, -8.9323e-02, -5.5065e-01, -9.4051e-01,  2.9254e-01,\n",
       "          -1.0367e-01,  8.4447e-01,  5.4255e-01, -5.1472e-01,  7.7902e-01,\n",
       "           7.6704e-01, -4.5420e-02, -7.3378e-01, -7.7203e-01, -9.7386e-01,\n",
       "           5.5901e-01, -6.3754e-01,  7.2630e-01, -7.1279e-01, -1.3299e-01,\n",
       "           2.1359e-01,  5.9856e-01, -3.3540e-01, -4.2143e-01,  9.3669e-01,\n",
       "          -4.4665e-01,  4.5575e-02, -4.1925e-01, -4.0237e-01, -2.4430e-01,\n",
       "           9.9352e-01,  8.0037e-01,  2.2767e-01, -5.8191e-02, -7.3426e-01,\n",
       "          -2.0946e-02,  8.0537e-01, -7.6747e-01,  7.7571e-01,  7.3419e-01,\n",
       "           9.7010e-01, -3.8967e-02, -5.4712e-01, -9.1631e-01, -1.1502e-01,\n",
       "           3.1504e-01,  5.4697e-01,  4.3342e-01, -8.6346e-01,  6.7235e-01,\n",
       "          -8.4988e-01, -3.8434e-02, -6.0753e-01, -7.0838e-01,  6.1141e-01,\n",
       "           6.0135e-02,  2.6997e-01, -2.1365e-01,  3.0759e-01, -7.0091e-01,\n",
       "          -8.4353e-01, -3.3173e-01,  2.2177e-01,  2.9964e-01, -7.4765e-01,\n",
       "          -7.7847e-01, -1.2498e-01,  2.0385e-02,  1.6405e-01,  3.9278e-01,\n",
       "           2.2615e-01, -3.5996e-01, -1.1913e-01, -9.9393e-01, -2.6538e-01,\n",
       "          -1.5410e-01,  5.2280e-01, -5.0202e-01, -1.2395e-01,  8.2800e-01,\n",
       "          -9.8686e-01, -5.9944e-01, -8.1007e-01, -1.6021e-01, -3.1711e-01,\n",
       "           3.0406e-01,  8.9144e-01, -4.4038e-01, -7.0565e-01,  1.8812e-01,\n",
       "           5.1311e-01,  3.2434e-01, -7.7067e-01,  7.7169e-01,  8.0237e-01,\n",
       "          -7.6407e-01,  6.5283e-01, -4.2463e-02,  9.4883e-01, -8.4985e-01],\n",
       "         [-1.9046e-01,  7.5730e-01,  6.1524e-01, -4.5717e-01, -6.4717e-01,\n",
       "          -3.4697e-01,  5.8733e-01,  7.8552e-01,  6.9011e-01, -1.0684e-01,\n",
       "          -2.9652e-01,  9.7344e-01,  8.1847e-01,  8.5154e-01, -3.0669e-01,\n",
       "          -6.4261e-01,  9.4967e-01,  7.3722e-01, -1.9928e-01,  9.5361e-01,\n",
       "           8.1329e-01, -9.5027e-01,  6.1277e-01, -7.0658e-01,  3.1357e-01,\n",
       "           2.4853e-01, -3.1811e-01, -2.3650e-01,  7.7033e-01, -3.2990e-01,\n",
       "           8.9083e-01,  2.0874e-02, -2.2285e-01, -3.2951e-01, -4.1823e-01,\n",
       "          -1.4219e-02, -9.7996e-02, -5.9989e-01, -6.6563e-01, -8.3294e-01,\n",
       "          -9.3301e-01, -5.4477e-01, -1.9101e-01, -6.9544e-02, -8.8120e-01,\n",
       "          -1.5746e-02, -5.3135e-01, -1.7271e-01,  9.0744e-01,  5.5860e-01,\n",
       "           5.8975e-01, -2.8786e-01,  9.2622e-01,  9.0936e-01, -1.9122e-01,\n",
       "           6.7543e-01, -1.1571e-01,  3.8914e-01,  1.0308e-01, -1.1494e-01,\n",
       "          -8.9969e-01,  4.3898e-01, -9.3964e-01,  4.3830e-01, -2.5326e-01,\n",
       "           5.6891e-01,  2.1308e-01, -9.6716e-01, -3.3982e-01, -5.9875e-01,\n",
       "          -6.0587e-01, -7.1797e-01,  1.4647e-01,  4.7992e-01, -8.0754e-01,\n",
       "           1.9357e-01, -4.6877e-01,  7.5608e-01, -6.7984e-02,  5.3961e-01,\n",
       "          -8.6975e-01,  2.2846e-01, -2.5054e-01,  5.9468e-01,  4.5508e-02,\n",
       "          -7.1026e-01,  6.0879e-01, -4.2674e-01,  9.3872e-01, -9.0121e-02,\n",
       "           8.7024e-02, -5.7269e-01,  9.0240e-01, -7.1218e-02, -5.8989e-01,\n",
       "           4.2019e-01, -8.8393e-01,  9.4166e-01,  5.6253e-01,  1.1161e-01],\n",
       "         [-3.6839e-02,  6.2968e-01,  9.8497e-01,  4.3158e-01,  6.2085e-01,\n",
       "          -5.0337e-01,  8.8469e-01,  4.4670e-01, -6.1165e-01,  5.1609e-01,\n",
       "           1.6153e-01, -5.0949e-01,  3.8937e-01, -3.1923e-01, -8.1845e-02,\n",
       "           2.5463e-01, -2.6522e-01,  8.0087e-01, -8.4914e-01, -4.0264e-01,\n",
       "          -5.0519e-01,  5.3936e-01,  1.2092e-01, -2.9845e-01, -4.5467e-01,\n",
       "          -6.0701e-01,  6.8732e-01, -1.2421e-01, -7.4322e-01,  3.1227e-01,\n",
       "          -9.3545e-01,  3.9429e-01,  6.6655e-01,  3.8846e-01, -7.8354e-01,\n",
       "           8.5950e-01,  2.7488e-01, -6.0306e-01,  5.2459e-01,  7.2491e-01,\n",
       "           3.7349e-01,  9.4242e-01, -6.3241e-01, -7.2459e-01, -1.2156e-01,\n",
       "           4.1672e-01,  4.1141e-01,  5.7390e-01, -4.8080e-01, -9.4225e-01,\n",
       "          -2.1355e-01, -3.2466e-01, -3.8220e-01,  7.5762e-02,  2.8398e-01,\n",
       "          -4.1308e-01, -5.5476e-01,  4.7216e-01,  5.0245e-01, -2.3969e-01,\n",
       "           7.0141e-01,  6.2642e-01,  1.6069e-01, -9.1573e-01,  2.6596e-01,\n",
       "          -8.9000e-01, -6.0133e-01, -8.8187e-01, -6.3562e-01, -5.0689e-01,\n",
       "           1.6815e-01, -6.5805e-01,  5.5207e-01,  8.8988e-01, -5.8811e-01,\n",
       "           3.3647e-01,  7.4904e-02, -6.2798e-01, -6.1177e-01,  7.2670e-01,\n",
       "          -9.5268e-01,  1.5260e-02, -5.5177e-01, -9.9979e-01,  6.3286e-01,\n",
       "           8.0155e-01, -3.0823e-02,  3.9951e-01, -4.7002e-01, -9.1113e-01,\n",
       "          -9.9584e-01, -8.7696e-01,  7.0199e-01, -6.8849e-02,  8.1719e-01,\n",
       "          -5.1377e-01, -2.8805e-02, -8.0425e-01, -5.6517e-01, -9.8948e-01],\n",
       "         [-8.0303e-01, -2.8753e-01, -5.4636e-01, -4.0127e-01, -1.5787e-01,\n",
       "          -3.0563e-01,  7.8749e-01, -5.8145e-01, -2.9680e-01, -8.2438e-01,\n",
       "           6.6635e-01,  2.8118e-04, -3.6123e-01,  7.3803e-01,  8.5784e-02,\n",
       "          -4.6676e-01,  7.2934e-01,  5.8697e-01,  4.4329e-01,  9.5147e-01,\n",
       "          -5.0244e-01,  7.8137e-02,  8.7404e-02,  8.5509e-01, -4.1054e-01,\n",
       "           8.9624e-01, -1.0073e-01, -1.5390e-01, -1.9325e-01, -1.7691e-01,\n",
       "          -9.2054e-01, -5.2854e-01, -2.0502e-01, -6.3494e-01,  2.5642e-01,\n",
       "           8.4963e-02, -1.7158e-01,  9.8716e-01, -2.1131e-01, -5.1401e-01,\n",
       "           4.9903e-01,  6.7143e-01,  5.5355e-01, -6.7048e-01,  6.3541e-01,\n",
       "           7.7477e-01, -6.8242e-01, -5.2155e-01, -8.9945e-01, -4.7375e-01,\n",
       "          -8.9938e-02, -5.1462e-02, -9.7023e-01,  9.5355e-01,  9.2339e-01,\n",
       "          -7.8448e-01,  7.2224e-01,  8.2872e-01, -3.5713e-01, -4.1367e-01,\n",
       "           3.3061e-01,  8.3911e-01, -1.1863e-01,  8.9232e-01, -2.5995e-01,\n",
       "           6.9675e-01, -3.8009e-01, -5.3455e-01,  7.0626e-01, -6.0255e-01,\n",
       "           5.4671e-01, -2.7765e-01,  4.3306e-01, -8.8694e-01, -8.5873e-01,\n",
       "           9.0524e-01, -9.4459e-01, -2.8397e-01, -1.1163e-01,  9.9498e-01,\n",
       "           6.7439e-02,  8.9110e-01, -9.5060e-01,  5.9359e-01, -7.7437e-01,\n",
       "           1.8224e-01, -8.5305e-02,  4.9306e-01, -8.1370e-01,  7.1257e-01,\n",
       "          -2.7407e-01, -9.2982e-01, -3.2845e-01,  5.6886e-01,  4.5176e-01,\n",
       "          -3.3085e-01,  8.6813e-02, -2.5340e-01, -5.2163e-01,  2.4470e-01]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = walk(polytope=hypercube,\n",
    "        X0 = x0,  \n",
    "        z=100, \n",
    "        T=1, \n",
    "        warm=0,\n",
    "        thinning=10000, \n",
    "        device= None, \n",
    "        seed=None,\n",
    "        verbosity=2\n",
    ")\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Fully dimensional Polytopes  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> $A^IX \\leq b^I$  \n",
    "> \n",
    "> $A^EX = b^E$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For non-fully dimensional polytopes we need to use the class `NFDPolytope` in the `mhar.polytope` module. The restrictions must be passed as pytorch tensors.  \n",
    "  \n",
    "We will sample the unit hypercube that is defined as:  \n",
    "> $n-simplex = \\{x \\in R^n || \\sum_{i=1}^{n} x_i = 1, 0 \\leq x_i \\} $  \n",
    "\n",
    "Which we can represent in matrix restrictions:  \n",
    "$ -Ix \\leq 0$  \n",
    "$ [1]^n = 1 $  \n",
    "Where $I$ is the identity matrix of dimension $n \\times n$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition-Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create the tensors to represent the restrictions that define the polytope. Since we need to create a projection matrix for the non-fully dimensional object we need to preserve the numerical stability of the algorithm, we suggest using 64 bits precision. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inequality Matrix A^I \n",
      " tensor([[-1., -0., -0.],\n",
      "        [-0., -1., -0.],\n",
      "        [-0., -0., -1.]], dtype=torch.float64) \n",
      "\n",
      "Inequality Vector b^I \n",
      " tensor([[0.],\n",
      "        [0.],\n",
      "        [0.]], dtype=torch.float64)\n",
      "\n",
      "Equality Matrix A^E \n",
      " tensor([[1., 1., 1.]], dtype=torch.float64) \n",
      "\n",
      "Equality Vector b^E \n",
      " tensor([[1.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "n = 3 # Dimension\n",
    "dtype = torch.float64 # Precision \n",
    "A_I = torch.eye(n).to(dtype) * -1.0\n",
    "b_I = torch.empty(n, 1, dtype=dtype)\n",
    "b_I.fill_(0.0)\n",
    "\n",
    "# Create Equalities\n",
    "A_E = torch.empty(1, n, dtype=dtype)\n",
    "A_E.fill_(1.0)\n",
    "b_E = torch.empty(1, 1, dtype=dtype)\n",
    "b_E.fill_(1.0)      \n",
    "print(f'Inequality Matrix A^I \\n {A_I} \\n')\n",
    "print(f'Inequality Vector b^I \\n {b_I}\\n')\n",
    "print(f'Equality Matrix A^E \\n {A_E} \\n')\n",
    "print(f'Equality Vector b^E \\n {b_E}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets create a `NFDPolytope` object to represent the polytope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/uumami/sonder.art/mhar/mhar/polytope.py:45: UserWarning:\n",
      "  The object will not create a copy of the tensors, so modifications will be reflected in the object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mhar.polytope import NFDPolytope\n",
    "simplex = NFDPolytope(A_I, # Inequality Restriction Matrix \n",
    "                     b_I,  # Inequality Vector\n",
    "                     A_E, # Equality Restriction Matrix \n",
    "                     b_E,  # Equality Vector\n",
    "                     dtype, # torch dtype\n",
    "                     device, # device used cpu or cuda\n",
    "                     copy=False # bool for creating a copy of the restrictions\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Numeric Precision (dtype) torch.float64\n",
       "Device: cuda\n",
       "A_in: torch.Size([3, 3]) \n",
       "b_in: torch.Size([3, 1])\n",
       "A_eq: torch.Size([1, 3]) \n",
       "b_eq: torch.Size([1, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simplex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projection Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to compute que projection matrix that we will use for projecting the random directions vectors to the equality space. For that we can use the method `NFDPolytope.compute_projection_matrix()`. We recommend using the highest precision possible to compute this matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max non zero error for term (A A')^(-1)A at precision torch.float64:  tensor(0., device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "simplex.compute_projection_matrix(device=device, solver_precision=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Numeric Precision (dtype) torch.float64\n",
       "Device: cuda\n",
       "A_in: torch.Size([3, 3]) \n",
       "b_in: torch.Size([3, 1])\n",
       "A_eq: torch.Size([1, 3]) \n",
       "b_eq: torch.Size([1, 1])\n",
       "Projection Matrix: torch.Size([3, 3])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simplex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting Inner Point(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to start the algorithm we need at least one inner point $x_0$. If you know your inner point you can supply it to the algorithm, `mhar` also contains functions to compute one inner point using the [chebyshev center](https://en.wikipedia.org/wiki/Chebyshev_center) which finds the center of the smallest ball inside the polytope.\n",
    "\n",
    " `from mhar.inner_point import ChebyshevCenter`. The solver is in numpy so precision must be specified as `numpy.dtype`. It uses `linprog` from `scipy.optimize`. You can see the documentation [here](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.linprog.html). \n",
    "  \n",
    "It could also be the last points produced by a previous walk/run of the `mhar` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mhar.inner_point import ChebyshevCenter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Simplex Status for the Chebyshev Center\n",
      " Optimization proceeding nominally.\n"
     ]
    }
   ],
   "source": [
    "x0 = ChebyshevCenter(polytope=simplex, # Polytope Object\n",
    "                    lb=None,  # Lowerbound (lb <= x ), if unknown leave it as None \n",
    "                    ub=None,  # Upperbound ( x <= up), if unknown leave it as None \n",
    "                    tolerance=1e-4, # Tolerance for equality restrictions (A_eqx = b_eq)\n",
    "                    device='cuda', # device used cpu or cuda\n",
    "                    solver_precision=np.float64 # numpy dtype\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3333],\n",
       "        [0.3333],\n",
       "        [0.3333]], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to manually input the inner points then it is enough to use a torch tensor of size $n \\times l$. Where $l$ is ne number of inner points you want to supply. Just write them in column notation.  \n",
    "  \n",
    "We are going to manually add an other starting point to the one calcualted by the `chebyshev center` to show its functionality later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3333, 0.2500],\n",
       "        [0.3333, 0.2500],\n",
       "        [0.3333, 0.5000]], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0 = torch.cat([x0, \n",
    "            torch.tensor([[.25], [.25], [.5]]).to(device).to(dtype)\n",
    "             ], dim=1)\n",
    "x0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can proceed to sample the `polytope`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Walk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to sample the polytope starting from the inner points we supply using the method `walk.walk`. It has the next arguments:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ `polytope` is an object of the type `Polytope` or `NFDPolytope` that defines it.\n",
    "+ `X0` a tensor containing the inner points to start the walks from.\n",
    "+ `z` determines the number of simoultaneous `walks`. If the number of initial points supplied are less than `z`  ($ncols($ `x0` $) < $ `z`) then some points will be reused as starting points.  \n",
    "+ `T` is the number of uncorrelated iterations you want. The number of total uncorrelated points produced by the algorithm is `z` $\\times$ `T`, since `z` points are sampled at each iteration.  \n",
    "+ `thinning` determines the number of points that we need to burn between iterations in order to get uncorrelated points. The suggested factor should be in the order of $O(n^3)$.\n",
    "+ `warm` determines a thinning for warming the walks only at the beggining, after the this war the walks resumes as normal. It is used if you want to lose the dependency from the starting points.\n",
    "+ `device` device where the tenros live `cpu` or `cuda`\n",
    "+ `seed` for reproducibility\n",
    "+ `verbosity` for printing what is going on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.],\n",
       "        [-0.],\n",
       "        [-0.],\n",
       "        [-0.],\n",
       "        [-0.],\n",
       "        [-0.],\n",
       "        [-0.],\n",
       "        [-0.],\n",
       "        [-0.],\n",
       "        [-0.]], device='cuda:0')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmhar\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwalk\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m walk\n\u001b[0;32m----> 2\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mwalk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpolytope\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msimplex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX0\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mT\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthinning\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sonder.art/mhar/mhar/walk.py:143\u001b[0m, in \u001b[0;36mwalk\u001b[0;34m(polytope, X0, z, T, warm, thinning, device, seed, verbosity)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m(device \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m]), \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe device is not correctly specified: \u001b[39m\u001b[38;5;124m'\u001b[39m, device,\n\u001b[1;32m    141\u001b[0m                                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Please choose cpu or cuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# X0 dimension\u001b[39;00m\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m(X0\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m polytope\u001b[38;5;241m.\u001b[39mn)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;66;03m## Set min and max values\u001b[39;00m\n\u001b[1;32m    146\u001b[0m min_ \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfinfo(polytope\u001b[38;5;241m.\u001b[39mdtype)\u001b[38;5;241m.\u001b[39mmin \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from mhar.walk import walk\n",
    "X = walk(polytope=simplex,\n",
    "        X0 = x0,  \n",
    "        z=100, \n",
    "        T=10, \n",
    "        warm=0,\n",
    "        thinning=n**3, \n",
    "        device=device, \n",
    "        seed=None,\n",
    "        verbosity=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`walk` produces `T` $\\times$ `z` uncorrelated points. It returns a vector of dimension `T` $\\times$ `z` $\\times$ `n`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.4841e-01,  6.8280e-01,  4.5665e-02, -5.0482e-01,  8.0002e-01,\n",
       "           8.4413e-01,  7.0327e-01,  8.1021e-01, -5.8382e-02,  8.6097e-01,\n",
       "          -4.0612e-01, -1.5000e-01, -7.2603e-01,  9.1046e-01,  5.8878e-01,\n",
       "           4.3969e-01, -8.7148e-01,  2.2590e-01,  4.2120e-01,  8.2291e-01,\n",
       "          -4.3603e-01, -8.6074e-01,  4.7400e-01, -5.4297e-01,  9.2238e-02,\n",
       "           1.3477e-01,  8.7554e-01,  1.8995e-01,  6.9708e-01,  2.0776e-01,\n",
       "          -3.8575e-01,  8.0821e-01,  7.2754e-01, -7.9290e-01, -5.0327e-01,\n",
       "           3.3527e-01, -4.2698e-01,  7.7645e-01, -1.9216e-01,  7.3043e-02,\n",
       "           2.5659e-01,  3.5802e-01, -1.4228e-01, -3.6713e-01, -1.7050e-01,\n",
       "          -7.3152e-01, -1.6744e-01,  1.9559e-01,  7.7014e-01, -7.0855e-01,\n",
       "           6.1163e-01,  7.4568e-01,  4.3088e-01,  9.6311e-01, -2.0932e-01,\n",
       "          -1.2013e-01,  1.1033e-01,  1.1165e-02, -1.2734e-01,  6.2316e-01,\n",
       "           4.2978e-01,  4.6269e-01, -1.4436e-01,  1.8806e-01, -3.2818e-01,\n",
       "          -7.5972e-01,  7.6973e-01,  2.9854e-01, -5.1324e-01, -3.8139e-01,\n",
       "           2.5968e-01, -4.5009e-01,  7.2078e-01, -7.7590e-01,  6.9018e-01,\n",
       "           3.6892e-01, -2.0498e-01, -7.6132e-01, -8.7373e-01,  4.5159e-01,\n",
       "          -3.4228e-01,  2.2593e-01, -9.4325e-01,  5.4446e-01, -2.8797e-01,\n",
       "          -1.8239e-01,  3.8148e-01,  4.9246e-01, -3.2733e-01, -3.3301e-01,\n",
       "          -2.2546e-01, -2.2405e-01,  9.4811e-01, -8.3690e-01,  1.5775e-02,\n",
       "           1.8853e-03, -5.1452e-01, -3.6917e-01,  2.1077e-01, -2.6284e-02],\n",
       "         [-2.3846e-01,  8.2253e-01,  8.5440e-01,  6.5758e-01,  3.3988e-01,\n",
       "           3.5029e-01, -6.6900e-01,  5.2681e-01,  6.2312e-01, -1.5460e-01,\n",
       "          -3.4945e-01,  8.8610e-01,  7.2138e-01,  4.2899e-01, -6.3952e-01,\n",
       "           5.6993e-01, -3.1186e-01, -4.6011e-02,  7.4016e-01,  2.9680e-01,\n",
       "           4.7177e-01, -6.1193e-02,  5.2712e-02,  5.8172e-01, -6.2818e-01,\n",
       "           1.6382e-01, -7.1934e-01,  2.9893e-01, -3.1561e-01,  1.8976e-01,\n",
       "           9.2561e-01, -3.2743e-01,  2.2378e-01, -7.4811e-01, -6.2333e-01,\n",
       "          -3.3864e-01,  6.0817e-01, -1.2991e-01, -8.4464e-01, -7.6701e-01,\n",
       "          -4.7529e-01, -4.6685e-01, -4.4186e-01, -5.1870e-01,  2.4627e-01,\n",
       "          -1.4043e-01,  5.1771e-01, -2.2173e-01, -2.6738e-01,  6.0693e-01,\n",
       "          -8.2063e-02,  3.3623e-01,  7.1629e-01, -6.0301e-01,  7.8522e-01,\n",
       "          -2.7171e-01, -7.1037e-01, -7.4426e-01,  3.9159e-01,  2.3084e-01,\n",
       "          -4.9674e-01,  2.5091e-01, -8.9045e-01,  8.6441e-02, -5.0741e-01,\n",
       "          -4.5634e-01,  4.0251e-01, -6.7902e-01,  5.4625e-01,  1.1018e-01,\n",
       "          -6.4149e-01,  5.4333e-01,  4.2186e-01, -4.6781e-01, -5.1179e-01,\n",
       "          -4.4160e-01,  1.4893e-01, -1.8455e-01, -2.1803e-01,  4.3072e-01,\n",
       "           5.4954e-01, -3.4434e-01,  1.8455e-01, -3.2940e-02, -5.9305e-01,\n",
       "           1.3843e-01,  7.6463e-01,  2.2529e-01, -4.1457e-01,  9.8649e-01,\n",
       "          -2.9173e-01,  9.8376e-01,  6.6224e-01, -6.9712e-01, -1.2326e-01,\n",
       "          -9.6339e-01,  8.4637e-01, -4.8975e-01,  7.8790e-01, -4.4637e-01],\n",
       "         [-2.8180e-01,  4.3395e-01, -8.0663e-01, -5.1516e-01, -1.0538e-01,\n",
       "          -5.9754e-01, -1.7448e-01,  5.6907e-01, -3.1037e-01,  8.5556e-02,\n",
       "           5.2647e-01,  8.3231e-02, -5.1439e-01, -4.2408e-01,  4.6449e-01,\n",
       "          -6.0909e-01,  1.0421e-02, -1.8180e-01,  2.4343e-01,  6.0497e-01,\n",
       "          -7.1110e-01, -5.1142e-01,  6.5041e-01, -3.0985e-01, -4.7911e-02,\n",
       "          -6.0554e-01,  9.8278e-01,  4.5852e-01,  2.0523e-01, -4.3632e-01,\n",
       "          -6.6868e-01, -3.0025e-01,  4.7404e-01,  7.3797e-01,  3.8265e-02,\n",
       "           7.8291e-01, -2.9568e-01, -7.1074e-02, -1.4283e-01, -1.9786e-01,\n",
       "           6.4950e-01, -2.1007e-01,  4.7621e-01,  3.8476e-02,  1.3847e-01,\n",
       "          -4.6294e-02,  1.9972e-01,  6.2057e-01,  3.0422e-01,  9.4513e-01,\n",
       "          -3.4252e-01,  5.0002e-01,  1.9129e-01, -6.1927e-01,  9.1843e-01,\n",
       "           5.5037e-01,  5.8855e-01, -8.3389e-01,  9.5488e-02, -6.4623e-01,\n",
       "          -7.7749e-01,  9.7452e-02,  6.8476e-01,  4.0740e-01, -6.7750e-01,\n",
       "           3.4784e-01,  4.7034e-01,  8.8114e-01,  4.3372e-01, -1.9699e-01,\n",
       "          -4.7420e-01, -2.1443e-01, -7.6799e-01,  9.1599e-01, -1.1707e-01,\n",
       "           6.0044e-02,  6.6573e-01,  8.7315e-01, -2.2257e-01, -9.1803e-01,\n",
       "           3.3982e-01,  4.5053e-01, -9.7353e-01,  5.8399e-01, -8.6541e-01,\n",
       "           7.2302e-01, -2.7623e-01, -6.6217e-01,  8.4258e-01,  4.1891e-01,\n",
       "           7.2895e-01, -5.2852e-01, -1.8584e-01, -9.9346e-01,  8.1482e-01,\n",
       "          -9.5339e-02, -9.8388e-01,  8.9688e-01,  2.1017e-03,  9.6716e-01],\n",
       "         [ 9.6050e-01, -2.6711e-01, -3.8024e-01,  2.0872e-02, -1.2363e-01,\n",
       "           8.1055e-01, -6.3538e-01, -2.8192e-01,  3.2118e-01, -8.8104e-01,\n",
       "           6.1221e-01, -7.5254e-01, -3.9962e-01, -5.4036e-02, -7.8648e-01,\n",
       "          -3.0896e-01, -6.8282e-01,  1.4110e-01,  1.6437e-01,  4.3244e-01,\n",
       "          -3.9471e-01,  3.8827e-01, -5.2568e-01, -6.3093e-02, -8.0298e-01,\n",
       "          -6.3575e-01, -2.9366e-01,  4.1089e-01,  3.9295e-01, -9.4403e-02,\n",
       "          -1.1512e-01,  5.7874e-01, -1.9369e-01, -4.7389e-01,  9.7404e-01,\n",
       "          -1.8574e-01,  5.9605e-01, -5.8073e-01,  1.3798e-01,  3.3806e-01,\n",
       "          -8.1759e-01,  1.0842e-01, -4.9541e-01, -1.0629e-01, -8.4708e-01,\n",
       "          -1.6561e-01, -1.3013e-01, -9.5233e-01,  8.9233e-01, -1.0060e-01,\n",
       "          -6.9876e-01,  1.1541e-02, -1.4426e-01, -2.3232e-01, -6.3873e-01,\n",
       "           9.1534e-01, -5.8676e-01, -1.8829e-01, -2.6476e-01, -1.7948e-01,\n",
       "           3.1673e-01,  1.5114e-01,  2.3441e-01,  5.3755e-01,  2.0543e-01,\n",
       "          -1.8287e-01,  9.7198e-01, -4.4451e-01, -1.6734e-01,  8.7596e-01,\n",
       "          -2.3407e-01,  9.9272e-01, -1.4095e-02, -3.1891e-01,  1.4838e-01,\n",
       "          -5.9045e-01, -3.6445e-01, -2.9198e-01,  8.3040e-01, -9.0325e-01,\n",
       "           7.9677e-01, -9.1550e-01, -7.7937e-01, -3.1393e-01, -2.9727e-01,\n",
       "           9.5244e-01,  7.5851e-01,  9.6994e-01, -7.6244e-01, -5.9783e-01,\n",
       "          -4.4636e-01,  4.2284e-01, -1.1290e-01,  7.2191e-01,  1.4305e-01,\n",
       "           4.3496e-01, -2.0963e-01,  3.0092e-01,  3.4801e-01,  3.1351e-01],\n",
       "         [ 5.9746e-02,  7.6871e-01, -7.7457e-01,  4.5455e-01,  4.5420e-01,\n",
       "          -8.0929e-02,  5.4416e-01,  1.3686e-01,  1.5591e-01,  5.5497e-01,\n",
       "          -4.5677e-01,  3.7446e-01, -3.5184e-01, -5.8070e-01, -4.2220e-01,\n",
       "          -8.6046e-01, -2.4690e-01,  1.4410e-01, -6.0964e-01,  3.1406e-01,\n",
       "           2.3742e-01,  6.5708e-01, -8.3638e-01, -9.4234e-01,  5.1371e-01,\n",
       "          -7.4466e-01,  2.3891e-01,  7.9388e-01,  3.3493e-01, -4.5024e-01,\n",
       "           1.9997e-01,  3.6984e-01, -9.2219e-01, -4.2533e-01,  2.3006e-01,\n",
       "          -1.9715e-01, -4.9414e-01,  4.9619e-01,  4.6823e-01, -7.7329e-01,\n",
       "           3.3209e-01,  4.4676e-01, -1.8533e-01, -4.5642e-01, -8.1653e-01,\n",
       "           4.6019e-01, -1.2216e-01, -1.5667e-01,  1.0833e-01,  5.5329e-01,\n",
       "           5.6929e-01,  8.7922e-01,  2.9568e-01, -1.6633e-01, -7.1468e-01,\n",
       "          -3.2781e-01, -5.6558e-01, -6.9192e-01,  2.8940e-01,  1.7665e-01,\n",
       "          -5.2889e-01,  9.8583e-01, -3.5663e-01, -6.3799e-01,  5.7986e-01,\n",
       "          -5.1272e-01,  8.2889e-01,  8.1271e-01,  1.4830e-01,  9.5110e-01,\n",
       "           1.7624e-01, -5.3262e-01,  6.0108e-01, -8.5457e-01, -2.9233e-01,\n",
       "          -9.4368e-01,  8.5084e-01,  9.9074e-01, -4.3353e-01, -6.4275e-01,\n",
       "          -2.5224e-01, -6.8453e-01, -4.9411e-02,  8.7990e-01,  5.3102e-02,\n",
       "          -3.8450e-01, -9.4766e-01,  2.1363e-01,  5.6493e-01,  6.0519e-01,\n",
       "           4.9080e-01, -3.3782e-01,  9.8496e-01,  7.8973e-02, -8.0192e-01,\n",
       "          -4.0869e-01,  9.8807e-01, -4.4891e-01, -4.8795e-01, -2.9762e-01],\n",
       "         [-5.8953e-01, -2.1225e-01, -4.1505e-01, -6.5248e-01, -5.0999e-01,\n",
       "           7.4506e-01,  8.9720e-01, -6.4744e-01, -8.0735e-02,  6.8364e-01,\n",
       "          -2.9870e-01,  6.7587e-01,  6.0141e-01, -7.6717e-01, -6.1998e-01,\n",
       "          -3.6200e-02,  8.5372e-01, -5.6636e-01, -3.8586e-01, -1.2497e-01,\n",
       "           3.5092e-01, -9.9438e-01, -4.7389e-01,  3.9745e-01,  7.7163e-01,\n",
       "           8.7639e-01, -7.7290e-01,  5.0334e-01,  9.2712e-01, -3.2946e-01,\n",
       "           9.4369e-03,  6.0302e-01,  8.7342e-01, -6.7215e-01,  7.7111e-01,\n",
       "           4.7997e-01, -8.2341e-01,  1.1440e-01,  5.5977e-01,  4.0122e-01,\n",
       "          -6.4571e-01, -7.8309e-01,  4.8773e-01,  2.3316e-01,  9.0812e-01,\n",
       "           9.1003e-01,  8.4799e-01,  3.2665e-01, -7.9431e-01,  5.8948e-01,\n",
       "          -5.1444e-02,  4.8517e-02, -4.4054e-01,  5.5022e-01, -8.5606e-01,\n",
       "          -4.2462e-01, -7.4040e-01,  1.8805e-01, -5.6073e-02, -6.8829e-01,\n",
       "           6.9801e-01,  8.5683e-01, -4.3776e-01, -2.0627e-01,  7.1524e-01,\n",
       "           5.9645e-01,  2.8252e-02, -3.8129e-01, -8.3826e-01,  9.3582e-01,\n",
       "          -4.2253e-01, -9.1054e-01, -1.8207e-01, -5.0964e-01,  7.7783e-01,\n",
       "           2.2861e-01, -6.2699e-01, -1.1594e-01,  7.5704e-01,  8.8875e-03,\n",
       "          -2.3610e-01, -6.7986e-01,  2.0837e-01, -2.4092e-01,  9.4990e-01,\n",
       "           2.7947e-01, -8.1332e-01,  4.5465e-01, -2.6139e-01,  8.1422e-01,\n",
       "          -8.3017e-01, -9.9724e-01, -6.7785e-01, -5.3172e-01,  3.0565e-01,\n",
       "          -9.7867e-01,  3.5078e-01, -8.8108e-01,  3.8276e-01, -8.9372e-01],\n",
       "         [ 2.9803e-01,  2.4023e-01, -7.7471e-01,  6.5107e-01,  7.0380e-02,\n",
       "          -6.3918e-01, -8.4483e-01,  7.2314e-01, -4.0540e-01,  6.5788e-01,\n",
       "          -6.5634e-04,  6.2973e-01, -2.3363e-01,  5.3304e-01,  8.0863e-01,\n",
       "           5.8581e-01, -1.1787e-01,  4.2332e-01, -9.9509e-01, -7.1770e-02,\n",
       "          -9.1043e-01,  1.7440e-01,  6.3664e-02, -7.1873e-01,  8.5424e-01,\n",
       "           9.7016e-01,  6.9307e-01,  5.1737e-01,  4.1836e-01, -3.4409e-01,\n",
       "          -4.9924e-01, -6.8495e-01, -1.5314e-01,  6.7162e-01, -6.4814e-01,\n",
       "          -5.1442e-01, -9.4811e-01, -3.9706e-02, -3.4723e-01, -9.7601e-02,\n",
       "          -3.4547e-01,  8.2438e-01, -6.6513e-01,  2.8342e-01,  9.1875e-01,\n",
       "          -1.8967e-03,  1.2822e-02, -8.0631e-01,  5.8506e-01,  4.5994e-01,\n",
       "           1.2307e-01, -7.0189e-01, -9.8656e-01, -5.4729e-01, -1.8481e-01,\n",
       "          -6.7007e-01,  9.1003e-01, -7.5408e-01, -2.2945e-01, -7.9961e-01,\n",
       "          -5.6129e-01,  2.6674e-01, -8.8824e-01,  8.4637e-01, -6.0679e-01,\n",
       "          -6.4588e-01, -7.9696e-01,  8.6921e-01, -6.1999e-01, -1.7048e-02,\n",
       "           8.8962e-02,  3.6923e-01,  7.7103e-01,  5.8906e-01, -2.8824e-01,\n",
       "           1.1367e-01, -1.5320e-01,  9.8427e-01,  4.5596e-01,  6.9617e-01,\n",
       "          -1.5251e-02, -7.6331e-01,  1.3491e-02,  3.5593e-02, -1.9600e-01,\n",
       "           1.1702e-02, -9.3442e-01,  7.2512e-01, -7.1126e-02, -2.2502e-01,\n",
       "           5.3784e-01,  8.8439e-01,  6.6879e-02,  5.9772e-01, -7.0853e-01,\n",
       "          -4.5029e-01, -7.9355e-01, -1.6351e-02, -7.8260e-01,  3.1477e-01],\n",
       "         [ 9.4495e-01,  8.0489e-01, -6.2972e-01,  1.5849e-01, -1.3537e-01,\n",
       "          -3.3863e-01,  6.6902e-01, -8.0963e-01, -1.7639e-01, -7.7312e-01,\n",
       "           1.9507e-01,  1.8849e-01,  2.8237e-03, -3.9226e-01,  5.6506e-01,\n",
       "           9.3462e-01, -3.1939e-01, -8.1021e-01, -6.2642e-01, -1.0609e-01,\n",
       "          -5.8836e-01,  3.4178e-01, -1.9585e-01,  8.4018e-01, -3.7252e-01,\n",
       "          -7.0082e-01, -7.8296e-01,  5.0448e-01,  1.0642e-01,  4.9841e-01,\n",
       "          -9.9616e-01, -9.9377e-01, -5.9021e-03, -3.1504e-01,  2.7363e-01,\n",
       "           3.4498e-02, -3.5374e-01,  2.0036e-01, -3.6793e-01,  1.7388e-01,\n",
       "          -8.8502e-01, -5.9741e-01,  9.5610e-02,  9.8022e-01, -9.6918e-01,\n",
       "          -2.4546e-01,  6.5718e-01, -8.2952e-01, -9.0239e-01, -5.0098e-01,\n",
       "          -4.6861e-01,  3.2492e-01,  8.1707e-01,  5.0957e-01, -9.3791e-01,\n",
       "          -7.2403e-01, -9.4991e-01, -3.9381e-01,  1.5444e-01, -7.5452e-02,\n",
       "           1.8025e-01,  3.1553e-01, -5.6312e-03,  1.0641e-01, -9.9830e-01,\n",
       "          -3.6317e-01, -3.3251e-01,  5.2642e-01, -1.4636e-01, -8.5799e-01,\n",
       "          -1.7387e-03, -6.3598e-01, -5.4580e-01,  1.6731e-01, -5.9899e-01,\n",
       "          -5.1951e-01,  8.0210e-02,  8.6722e-02, -2.5460e-01,  4.1736e-02,\n",
       "          -7.4958e-01, -7.0607e-01,  4.3948e-01,  8.2681e-01, -3.7474e-01,\n",
       "          -6.2400e-01, -7.9098e-01,  8.3438e-01,  3.1918e-01,  6.5751e-01,\n",
       "           6.0672e-01, -1.6317e-01,  9.2568e-02, -1.1072e-01,  1.9341e-02,\n",
       "          -4.0810e-01,  9.3455e-01,  4.6021e-01,  5.7373e-01, -4.8133e-01],\n",
       "         [-6.1442e-01,  4.7591e-01, -6.1754e-01,  2.1028e-01, -5.6281e-01,\n",
       "          -7.2293e-01, -5.8113e-01, -8.8750e-02,  4.9978e-01,  4.5631e-01,\n",
       "           6.1516e-02, -7.7055e-01, -2.3010e-01, -6.3238e-01,  1.2352e-01,\n",
       "           1.0214e-01, -5.5856e-01, -9.6127e-01, -3.5245e-01,  5.5630e-01,\n",
       "          -7.8586e-01, -9.3700e-01, -8.3398e-01,  4.3255e-01,  1.5426e-01,\n",
       "          -6.2217e-01,  8.5856e-01, -8.5811e-01,  3.2058e-01, -7.6802e-01,\n",
       "          -1.2476e-01, -1.8118e-01,  2.1401e-01,  1.3476e-01,  7.5871e-01,\n",
       "           3.7357e-01, -5.6279e-01, -9.3597e-01, -9.7018e-01, -7.8272e-01,\n",
       "           7.6672e-01, -9.4057e-01,  3.3064e-01,  9.2305e-01, -2.7913e-01,\n",
       "           2.0344e-01, -9.1502e-01,  3.2717e-01,  5.7583e-01, -8.8092e-01,\n",
       "          -4.1562e-01,  4.4448e-01, -9.3078e-01, -8.4439e-02, -1.5814e-01,\n",
       "          -4.7934e-01, -4.5037e-01,  6.5614e-01,  1.1051e-01, -8.4286e-01,\n",
       "           1.4191e-01, -8.9785e-01, -5.1560e-01,  1.3432e-01, -3.5102e-01,\n",
       "          -3.4568e-01, -9.8753e-02,  7.7806e-01,  1.3542e-01,  9.9406e-01,\n",
       "           7.1205e-01, -3.8063e-01,  8.0511e-01, -2.3448e-01,  2.9166e-01,\n",
       "           8.9555e-01, -6.6131e-02,  8.0428e-01,  6.5566e-01, -3.6410e-02,\n",
       "          -1.4926e-01, -3.4177e-01, -8.2758e-01,  3.5131e-01, -3.4588e-01,\n",
       "           1.6659e-01,  7.2880e-01,  4.5388e-02, -5.8022e-01, -4.8545e-01,\n",
       "           1.0472e-01,  9.5628e-01,  6.6630e-01, -2.0903e-02, -8.1544e-02,\n",
       "          -6.4397e-01, -3.7551e-01, -8.6214e-01, -9.6948e-01, -8.9897e-01],\n",
       "         [-9.8133e-02, -7.8589e-02,  5.5933e-01,  3.0497e-01, -6.8097e-01,\n",
       "          -1.6044e-01,  3.4499e-01, -3.8229e-01,  4.8806e-01, -8.1938e-01,\n",
       "          -3.2323e-01, -6.8975e-01, -4.3120e-01,  7.3553e-01,  8.9796e-01,\n",
       "          -1.0428e-01, -3.9348e-01, -6.5588e-01,  6.3766e-01, -9.0352e-01,\n",
       "           4.1658e-01,  5.6867e-01, -9.6661e-01, -9.8626e-01,  2.0883e-02,\n",
       "          -1.5976e-01,  2.1741e-01, -3.8847e-01, -8.2527e-01,  2.3344e-01,\n",
       "           4.7381e-01, -4.0818e-01, -6.1965e-02,  9.7325e-02, -6.5776e-01,\n",
       "          -3.4670e-01,  7.9799e-02, -5.5697e-01, -7.3260e-01, -2.2359e-02,\n",
       "          -5.3407e-01,  7.3371e-01,  7.3327e-01,  7.1427e-01, -4.9532e-01,\n",
       "           7.8406e-01,  2.5086e-01, -4.3917e-02,  6.5512e-02,  5.2642e-01,\n",
       "          -2.7105e-01,  1.3054e-01,  5.5375e-01,  4.1288e-01,  8.2844e-01,\n",
       "           2.9120e-01, -1.6284e-01,  1.8582e-01, -1.0056e-01,  4.6607e-01,\n",
       "           3.5127e-01, -3.6924e-01, -6.6026e-01,  9.0199e-01,  4.8383e-01,\n",
       "           1.1351e-01, -5.4637e-01, -9.2645e-01,  1.7305e-01, -5.9245e-01,\n",
       "           2.1925e-01, -1.7780e-01, -9.5735e-01, -1.7919e-01,  6.1984e-01,\n",
       "          -5.0473e-01, -5.8606e-01, -8.0632e-02,  6.4087e-01, -2.1436e-01,\n",
       "           9.6548e-01,  6.1861e-01,  1.3892e-01, -5.5841e-01,  2.1694e-01,\n",
       "           2.9599e-01, -9.1716e-01, -4.3544e-01, -2.7032e-01,  3.8949e-01,\n",
       "          -9.2906e-01, -8.2945e-01,  1.7194e-01, -4.0724e-01,  3.1348e-01,\n",
       "           3.8673e-01,  9.5344e-01, -7.9103e-01, -4.7172e-01,  4.6104e-01]]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 100])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical Stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infinite:  tensor(0)\n",
      "Nans:   tensor(0)\n",
      "Inequality violation:   tensor(100)\n",
      "Inequality violation with tol:   tensor(100)\n"
     ]
    }
   ],
   "source": [
    "print('Infinite: ', (~torch.isfinite(X)).sum())\n",
    "print('Nans:  ',(torch.isnan(X)).sum())\n",
    "print('Inequality violation:  ',(X.sum(1)!=1.0).sum())\n",
    "print('Inequality violation with tol:  ',((X.sum(1)- 1.0).abs()>1e-).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To sumamrize the steps taken we can use the `polytope_examples` for creating a `Hypercube`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/uumami/sonder.art/mhar/mhar/polytope.py:45: UserWarning:\n",
      "  The object will not create a copy of the tensors, so modifications will be reflected in the object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mhar.polytope_examples import Hypercube\n",
    "\n",
    "# Create a polytope (Hypercube)\n",
    "hypercube = Hypercube(10,\n",
    "                      dtype=torch.float32,\n",
    "                      device='cuda'\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define/Find inner points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Simplex Status for the Chebyshev Center\n",
      " Optimization proceeding nominally.\n"
     ]
    }
   ],
   "source": [
    "x0 = ChebyshevCenter(polytope=hypercube, \n",
    "                    lb=None, \n",
    "                    ub=None, \n",
    "                    tolerance=1e-4,\n",
    "                    device='cuda',\n",
    "                    solver_precision=np.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum number allowed -3.4028234663852886e+38\n",
      "Maximum number allowed 3.4028234663852886e+38\n",
      "Eps:  1.1920928955078125e-07\n",
      "Values close to zero will be converted to 3eps or -3eps: 3.5762786865234375e-07\n",
      "n:  10   mI: 20   mE: None   z: 100\n",
      "% of burned samples |█-----------------------------| 5.1%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of burned samples |██████████████████████████████| 100.0%\n",
      "% of iid samples |██████████████████████████████| 100.0%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.4841e-01,  6.8280e-01,  4.5665e-02, -5.0482e-01,  8.0002e-01,\n",
       "           8.4413e-01,  7.0327e-01,  8.1021e-01, -5.8382e-02,  8.6097e-01,\n",
       "          -4.0612e-01, -1.5000e-01, -7.2603e-01,  9.1046e-01,  5.8878e-01,\n",
       "           4.3969e-01, -8.7148e-01,  2.2590e-01,  4.2120e-01,  8.2291e-01,\n",
       "          -4.3603e-01, -8.6074e-01,  4.7400e-01, -5.4297e-01,  9.2238e-02,\n",
       "           1.3477e-01,  8.7554e-01,  1.8995e-01,  6.9708e-01,  2.0776e-01,\n",
       "          -3.8575e-01,  8.0821e-01,  7.2754e-01, -7.9290e-01, -5.0327e-01,\n",
       "           3.3527e-01, -4.2698e-01,  7.7645e-01, -1.9216e-01,  7.3043e-02,\n",
       "           2.5659e-01,  3.5802e-01, -1.4228e-01, -3.6713e-01, -1.7050e-01,\n",
       "          -7.3152e-01, -1.6744e-01,  1.9559e-01,  7.7014e-01, -7.0855e-01,\n",
       "           6.1163e-01,  7.4568e-01,  4.3088e-01,  9.6311e-01, -2.0932e-01,\n",
       "          -1.2013e-01,  1.1033e-01,  1.1165e-02, -1.2734e-01,  6.2316e-01,\n",
       "           4.2978e-01,  4.6269e-01, -1.4436e-01,  1.8806e-01, -3.2818e-01,\n",
       "          -7.5972e-01,  7.6973e-01,  2.9854e-01, -5.1324e-01, -3.8139e-01,\n",
       "           2.5968e-01, -4.5009e-01,  7.2078e-01, -7.7590e-01,  6.9018e-01,\n",
       "           3.6892e-01, -2.0498e-01, -7.6132e-01, -8.7373e-01,  4.5159e-01,\n",
       "          -3.4228e-01,  2.2593e-01, -9.4325e-01,  5.4446e-01, -2.8797e-01,\n",
       "          -1.8239e-01,  3.8148e-01,  4.9246e-01, -3.2733e-01, -3.3301e-01,\n",
       "          -2.2546e-01, -2.2405e-01,  9.4811e-01, -8.3690e-01,  1.5775e-02,\n",
       "           1.8853e-03, -5.1452e-01, -3.6917e-01,  2.1077e-01, -2.6284e-02],\n",
       "         [-2.3846e-01,  8.2253e-01,  8.5440e-01,  6.5758e-01,  3.3988e-01,\n",
       "           3.5029e-01, -6.6900e-01,  5.2681e-01,  6.2312e-01, -1.5460e-01,\n",
       "          -3.4945e-01,  8.8610e-01,  7.2138e-01,  4.2899e-01, -6.3952e-01,\n",
       "           5.6993e-01, -3.1186e-01, -4.6011e-02,  7.4016e-01,  2.9680e-01,\n",
       "           4.7177e-01, -6.1193e-02,  5.2712e-02,  5.8172e-01, -6.2818e-01,\n",
       "           1.6382e-01, -7.1934e-01,  2.9893e-01, -3.1561e-01,  1.8976e-01,\n",
       "           9.2561e-01, -3.2743e-01,  2.2378e-01, -7.4811e-01, -6.2333e-01,\n",
       "          -3.3864e-01,  6.0817e-01, -1.2991e-01, -8.4464e-01, -7.6701e-01,\n",
       "          -4.7529e-01, -4.6685e-01, -4.4186e-01, -5.1870e-01,  2.4627e-01,\n",
       "          -1.4043e-01,  5.1771e-01, -2.2173e-01, -2.6738e-01,  6.0693e-01,\n",
       "          -8.2063e-02,  3.3623e-01,  7.1629e-01, -6.0301e-01,  7.8522e-01,\n",
       "          -2.7171e-01, -7.1037e-01, -7.4426e-01,  3.9159e-01,  2.3084e-01,\n",
       "          -4.9674e-01,  2.5091e-01, -8.9045e-01,  8.6441e-02, -5.0741e-01,\n",
       "          -4.5634e-01,  4.0251e-01, -6.7902e-01,  5.4625e-01,  1.1018e-01,\n",
       "          -6.4149e-01,  5.4333e-01,  4.2186e-01, -4.6781e-01, -5.1179e-01,\n",
       "          -4.4160e-01,  1.4893e-01, -1.8455e-01, -2.1803e-01,  4.3072e-01,\n",
       "           5.4954e-01, -3.4434e-01,  1.8455e-01, -3.2940e-02, -5.9305e-01,\n",
       "           1.3843e-01,  7.6463e-01,  2.2529e-01, -4.1457e-01,  9.8649e-01,\n",
       "          -2.9173e-01,  9.8376e-01,  6.6224e-01, -6.9712e-01, -1.2326e-01,\n",
       "          -9.6339e-01,  8.4637e-01, -4.8975e-01,  7.8790e-01, -4.4637e-01],\n",
       "         [-2.8180e-01,  4.3395e-01, -8.0663e-01, -5.1516e-01, -1.0538e-01,\n",
       "          -5.9754e-01, -1.7448e-01,  5.6907e-01, -3.1037e-01,  8.5556e-02,\n",
       "           5.2647e-01,  8.3231e-02, -5.1439e-01, -4.2408e-01,  4.6449e-01,\n",
       "          -6.0909e-01,  1.0421e-02, -1.8180e-01,  2.4343e-01,  6.0497e-01,\n",
       "          -7.1110e-01, -5.1142e-01,  6.5041e-01, -3.0985e-01, -4.7911e-02,\n",
       "          -6.0554e-01,  9.8278e-01,  4.5852e-01,  2.0523e-01, -4.3632e-01,\n",
       "          -6.6868e-01, -3.0025e-01,  4.7404e-01,  7.3797e-01,  3.8265e-02,\n",
       "           7.8291e-01, -2.9568e-01, -7.1074e-02, -1.4283e-01, -1.9786e-01,\n",
       "           6.4950e-01, -2.1007e-01,  4.7621e-01,  3.8476e-02,  1.3847e-01,\n",
       "          -4.6294e-02,  1.9972e-01,  6.2057e-01,  3.0422e-01,  9.4513e-01,\n",
       "          -3.4252e-01,  5.0002e-01,  1.9129e-01, -6.1927e-01,  9.1843e-01,\n",
       "           5.5037e-01,  5.8855e-01, -8.3389e-01,  9.5488e-02, -6.4623e-01,\n",
       "          -7.7749e-01,  9.7452e-02,  6.8476e-01,  4.0740e-01, -6.7750e-01,\n",
       "           3.4784e-01,  4.7034e-01,  8.8114e-01,  4.3372e-01, -1.9699e-01,\n",
       "          -4.7420e-01, -2.1443e-01, -7.6799e-01,  9.1599e-01, -1.1707e-01,\n",
       "           6.0044e-02,  6.6573e-01,  8.7315e-01, -2.2257e-01, -9.1803e-01,\n",
       "           3.3982e-01,  4.5053e-01, -9.7353e-01,  5.8399e-01, -8.6541e-01,\n",
       "           7.2302e-01, -2.7623e-01, -6.6217e-01,  8.4258e-01,  4.1891e-01,\n",
       "           7.2895e-01, -5.2852e-01, -1.8584e-01, -9.9346e-01,  8.1482e-01,\n",
       "          -9.5339e-02, -9.8388e-01,  8.9688e-01,  2.1017e-03,  9.6716e-01],\n",
       "         [ 9.6050e-01, -2.6711e-01, -3.8024e-01,  2.0872e-02, -1.2363e-01,\n",
       "           8.1055e-01, -6.3538e-01, -2.8192e-01,  3.2118e-01, -8.8104e-01,\n",
       "           6.1221e-01, -7.5254e-01, -3.9962e-01, -5.4036e-02, -7.8648e-01,\n",
       "          -3.0896e-01, -6.8282e-01,  1.4110e-01,  1.6437e-01,  4.3244e-01,\n",
       "          -3.9471e-01,  3.8827e-01, -5.2568e-01, -6.3093e-02, -8.0298e-01,\n",
       "          -6.3575e-01, -2.9366e-01,  4.1089e-01,  3.9295e-01, -9.4403e-02,\n",
       "          -1.1512e-01,  5.7874e-01, -1.9369e-01, -4.7389e-01,  9.7404e-01,\n",
       "          -1.8574e-01,  5.9605e-01, -5.8073e-01,  1.3798e-01,  3.3806e-01,\n",
       "          -8.1759e-01,  1.0842e-01, -4.9541e-01, -1.0629e-01, -8.4708e-01,\n",
       "          -1.6561e-01, -1.3013e-01, -9.5233e-01,  8.9233e-01, -1.0060e-01,\n",
       "          -6.9876e-01,  1.1541e-02, -1.4426e-01, -2.3232e-01, -6.3873e-01,\n",
       "           9.1534e-01, -5.8676e-01, -1.8829e-01, -2.6476e-01, -1.7948e-01,\n",
       "           3.1673e-01,  1.5114e-01,  2.3441e-01,  5.3755e-01,  2.0543e-01,\n",
       "          -1.8287e-01,  9.7198e-01, -4.4451e-01, -1.6734e-01,  8.7596e-01,\n",
       "          -2.3407e-01,  9.9272e-01, -1.4095e-02, -3.1891e-01,  1.4838e-01,\n",
       "          -5.9045e-01, -3.6445e-01, -2.9198e-01,  8.3040e-01, -9.0325e-01,\n",
       "           7.9677e-01, -9.1550e-01, -7.7937e-01, -3.1393e-01, -2.9727e-01,\n",
       "           9.5244e-01,  7.5851e-01,  9.6994e-01, -7.6244e-01, -5.9783e-01,\n",
       "          -4.4636e-01,  4.2284e-01, -1.1290e-01,  7.2191e-01,  1.4305e-01,\n",
       "           4.3496e-01, -2.0963e-01,  3.0092e-01,  3.4801e-01,  3.1351e-01],\n",
       "         [ 5.9746e-02,  7.6871e-01, -7.7457e-01,  4.5455e-01,  4.5420e-01,\n",
       "          -8.0929e-02,  5.4416e-01,  1.3686e-01,  1.5591e-01,  5.5497e-01,\n",
       "          -4.5677e-01,  3.7446e-01, -3.5184e-01, -5.8070e-01, -4.2220e-01,\n",
       "          -8.6046e-01, -2.4690e-01,  1.4410e-01, -6.0964e-01,  3.1406e-01,\n",
       "           2.3742e-01,  6.5708e-01, -8.3638e-01, -9.4234e-01,  5.1371e-01,\n",
       "          -7.4466e-01,  2.3891e-01,  7.9388e-01,  3.3493e-01, -4.5024e-01,\n",
       "           1.9997e-01,  3.6984e-01, -9.2219e-01, -4.2533e-01,  2.3006e-01,\n",
       "          -1.9715e-01, -4.9414e-01,  4.9619e-01,  4.6823e-01, -7.7329e-01,\n",
       "           3.3209e-01,  4.4676e-01, -1.8533e-01, -4.5642e-01, -8.1653e-01,\n",
       "           4.6019e-01, -1.2216e-01, -1.5667e-01,  1.0833e-01,  5.5329e-01,\n",
       "           5.6929e-01,  8.7922e-01,  2.9568e-01, -1.6633e-01, -7.1468e-01,\n",
       "          -3.2781e-01, -5.6558e-01, -6.9192e-01,  2.8940e-01,  1.7665e-01,\n",
       "          -5.2889e-01,  9.8583e-01, -3.5663e-01, -6.3799e-01,  5.7986e-01,\n",
       "          -5.1272e-01,  8.2889e-01,  8.1271e-01,  1.4830e-01,  9.5110e-01,\n",
       "           1.7624e-01, -5.3262e-01,  6.0108e-01, -8.5457e-01, -2.9233e-01,\n",
       "          -9.4368e-01,  8.5084e-01,  9.9074e-01, -4.3353e-01, -6.4275e-01,\n",
       "          -2.5224e-01, -6.8453e-01, -4.9411e-02,  8.7990e-01,  5.3102e-02,\n",
       "          -3.8450e-01, -9.4766e-01,  2.1363e-01,  5.6493e-01,  6.0519e-01,\n",
       "           4.9080e-01, -3.3782e-01,  9.8496e-01,  7.8973e-02, -8.0192e-01,\n",
       "          -4.0869e-01,  9.8807e-01, -4.4891e-01, -4.8795e-01, -2.9762e-01],\n",
       "         [-5.8953e-01, -2.1225e-01, -4.1505e-01, -6.5248e-01, -5.0999e-01,\n",
       "           7.4506e-01,  8.9720e-01, -6.4744e-01, -8.0735e-02,  6.8364e-01,\n",
       "          -2.9870e-01,  6.7587e-01,  6.0141e-01, -7.6717e-01, -6.1998e-01,\n",
       "          -3.6200e-02,  8.5372e-01, -5.6636e-01, -3.8586e-01, -1.2497e-01,\n",
       "           3.5092e-01, -9.9438e-01, -4.7389e-01,  3.9745e-01,  7.7163e-01,\n",
       "           8.7639e-01, -7.7290e-01,  5.0334e-01,  9.2712e-01, -3.2946e-01,\n",
       "           9.4369e-03,  6.0302e-01,  8.7342e-01, -6.7215e-01,  7.7111e-01,\n",
       "           4.7997e-01, -8.2341e-01,  1.1440e-01,  5.5977e-01,  4.0122e-01,\n",
       "          -6.4571e-01, -7.8309e-01,  4.8773e-01,  2.3316e-01,  9.0812e-01,\n",
       "           9.1003e-01,  8.4799e-01,  3.2665e-01, -7.9431e-01,  5.8948e-01,\n",
       "          -5.1444e-02,  4.8517e-02, -4.4054e-01,  5.5022e-01, -8.5606e-01,\n",
       "          -4.2462e-01, -7.4040e-01,  1.8805e-01, -5.6073e-02, -6.8829e-01,\n",
       "           6.9801e-01,  8.5683e-01, -4.3776e-01, -2.0627e-01,  7.1524e-01,\n",
       "           5.9645e-01,  2.8252e-02, -3.8129e-01, -8.3826e-01,  9.3582e-01,\n",
       "          -4.2253e-01, -9.1054e-01, -1.8207e-01, -5.0964e-01,  7.7783e-01,\n",
       "           2.2861e-01, -6.2699e-01, -1.1594e-01,  7.5704e-01,  8.8875e-03,\n",
       "          -2.3610e-01, -6.7986e-01,  2.0837e-01, -2.4092e-01,  9.4990e-01,\n",
       "           2.7947e-01, -8.1332e-01,  4.5465e-01, -2.6139e-01,  8.1422e-01,\n",
       "          -8.3017e-01, -9.9724e-01, -6.7785e-01, -5.3172e-01,  3.0565e-01,\n",
       "          -9.7867e-01,  3.5078e-01, -8.8108e-01,  3.8276e-01, -8.9372e-01],\n",
       "         [ 2.9803e-01,  2.4023e-01, -7.7471e-01,  6.5107e-01,  7.0380e-02,\n",
       "          -6.3918e-01, -8.4483e-01,  7.2314e-01, -4.0540e-01,  6.5788e-01,\n",
       "          -6.5634e-04,  6.2973e-01, -2.3363e-01,  5.3304e-01,  8.0863e-01,\n",
       "           5.8581e-01, -1.1787e-01,  4.2332e-01, -9.9509e-01, -7.1770e-02,\n",
       "          -9.1043e-01,  1.7440e-01,  6.3664e-02, -7.1873e-01,  8.5424e-01,\n",
       "           9.7016e-01,  6.9307e-01,  5.1737e-01,  4.1836e-01, -3.4409e-01,\n",
       "          -4.9924e-01, -6.8495e-01, -1.5314e-01,  6.7162e-01, -6.4814e-01,\n",
       "          -5.1442e-01, -9.4811e-01, -3.9706e-02, -3.4723e-01, -9.7601e-02,\n",
       "          -3.4547e-01,  8.2438e-01, -6.6513e-01,  2.8342e-01,  9.1875e-01,\n",
       "          -1.8967e-03,  1.2822e-02, -8.0631e-01,  5.8506e-01,  4.5994e-01,\n",
       "           1.2307e-01, -7.0189e-01, -9.8656e-01, -5.4729e-01, -1.8481e-01,\n",
       "          -6.7007e-01,  9.1003e-01, -7.5408e-01, -2.2945e-01, -7.9961e-01,\n",
       "          -5.6129e-01,  2.6674e-01, -8.8824e-01,  8.4637e-01, -6.0679e-01,\n",
       "          -6.4588e-01, -7.9696e-01,  8.6921e-01, -6.1999e-01, -1.7048e-02,\n",
       "           8.8962e-02,  3.6923e-01,  7.7103e-01,  5.8906e-01, -2.8824e-01,\n",
       "           1.1367e-01, -1.5320e-01,  9.8427e-01,  4.5596e-01,  6.9617e-01,\n",
       "          -1.5251e-02, -7.6331e-01,  1.3491e-02,  3.5593e-02, -1.9600e-01,\n",
       "           1.1702e-02, -9.3442e-01,  7.2512e-01, -7.1126e-02, -2.2502e-01,\n",
       "           5.3784e-01,  8.8439e-01,  6.6879e-02,  5.9772e-01, -7.0853e-01,\n",
       "          -4.5029e-01, -7.9355e-01, -1.6351e-02, -7.8260e-01,  3.1477e-01],\n",
       "         [ 9.4495e-01,  8.0489e-01, -6.2972e-01,  1.5849e-01, -1.3537e-01,\n",
       "          -3.3863e-01,  6.6902e-01, -8.0963e-01, -1.7639e-01, -7.7312e-01,\n",
       "           1.9507e-01,  1.8849e-01,  2.8237e-03, -3.9226e-01,  5.6506e-01,\n",
       "           9.3462e-01, -3.1939e-01, -8.1021e-01, -6.2642e-01, -1.0609e-01,\n",
       "          -5.8836e-01,  3.4178e-01, -1.9585e-01,  8.4018e-01, -3.7252e-01,\n",
       "          -7.0082e-01, -7.8296e-01,  5.0448e-01,  1.0642e-01,  4.9841e-01,\n",
       "          -9.9616e-01, -9.9377e-01, -5.9021e-03, -3.1504e-01,  2.7363e-01,\n",
       "           3.4498e-02, -3.5374e-01,  2.0036e-01, -3.6793e-01,  1.7388e-01,\n",
       "          -8.8502e-01, -5.9741e-01,  9.5610e-02,  9.8022e-01, -9.6918e-01,\n",
       "          -2.4546e-01,  6.5718e-01, -8.2952e-01, -9.0239e-01, -5.0098e-01,\n",
       "          -4.6861e-01,  3.2492e-01,  8.1707e-01,  5.0957e-01, -9.3791e-01,\n",
       "          -7.2403e-01, -9.4991e-01, -3.9381e-01,  1.5444e-01, -7.5452e-02,\n",
       "           1.8025e-01,  3.1553e-01, -5.6312e-03,  1.0641e-01, -9.9830e-01,\n",
       "          -3.6317e-01, -3.3251e-01,  5.2642e-01, -1.4636e-01, -8.5799e-01,\n",
       "          -1.7387e-03, -6.3598e-01, -5.4580e-01,  1.6731e-01, -5.9899e-01,\n",
       "          -5.1951e-01,  8.0210e-02,  8.6722e-02, -2.5460e-01,  4.1736e-02,\n",
       "          -7.4958e-01, -7.0607e-01,  4.3948e-01,  8.2681e-01, -3.7474e-01,\n",
       "          -6.2400e-01, -7.9098e-01,  8.3438e-01,  3.1918e-01,  6.5751e-01,\n",
       "           6.0672e-01, -1.6317e-01,  9.2568e-02, -1.1072e-01,  1.9341e-02,\n",
       "          -4.0810e-01,  9.3455e-01,  4.6021e-01,  5.7373e-01, -4.8133e-01],\n",
       "         [-6.1442e-01,  4.7591e-01, -6.1754e-01,  2.1028e-01, -5.6281e-01,\n",
       "          -7.2293e-01, -5.8113e-01, -8.8750e-02,  4.9978e-01,  4.5631e-01,\n",
       "           6.1516e-02, -7.7055e-01, -2.3010e-01, -6.3238e-01,  1.2352e-01,\n",
       "           1.0214e-01, -5.5856e-01, -9.6127e-01, -3.5245e-01,  5.5630e-01,\n",
       "          -7.8586e-01, -9.3700e-01, -8.3398e-01,  4.3255e-01,  1.5426e-01,\n",
       "          -6.2217e-01,  8.5856e-01, -8.5811e-01,  3.2058e-01, -7.6802e-01,\n",
       "          -1.2476e-01, -1.8118e-01,  2.1401e-01,  1.3476e-01,  7.5871e-01,\n",
       "           3.7357e-01, -5.6279e-01, -9.3597e-01, -9.7018e-01, -7.8272e-01,\n",
       "           7.6672e-01, -9.4057e-01,  3.3064e-01,  9.2305e-01, -2.7913e-01,\n",
       "           2.0344e-01, -9.1502e-01,  3.2717e-01,  5.7583e-01, -8.8092e-01,\n",
       "          -4.1562e-01,  4.4448e-01, -9.3078e-01, -8.4439e-02, -1.5814e-01,\n",
       "          -4.7934e-01, -4.5037e-01,  6.5614e-01,  1.1051e-01, -8.4286e-01,\n",
       "           1.4191e-01, -8.9785e-01, -5.1560e-01,  1.3432e-01, -3.5102e-01,\n",
       "          -3.4568e-01, -9.8753e-02,  7.7806e-01,  1.3542e-01,  9.9406e-01,\n",
       "           7.1205e-01, -3.8063e-01,  8.0511e-01, -2.3448e-01,  2.9166e-01,\n",
       "           8.9555e-01, -6.6131e-02,  8.0428e-01,  6.5566e-01, -3.6410e-02,\n",
       "          -1.4926e-01, -3.4177e-01, -8.2758e-01,  3.5131e-01, -3.4588e-01,\n",
       "           1.6659e-01,  7.2880e-01,  4.5388e-02, -5.8022e-01, -4.8545e-01,\n",
       "           1.0472e-01,  9.5628e-01,  6.6630e-01, -2.0903e-02, -8.1544e-02,\n",
       "          -6.4397e-01, -3.7551e-01, -8.6214e-01, -9.6948e-01, -8.9897e-01],\n",
       "         [-9.8133e-02, -7.8589e-02,  5.5933e-01,  3.0497e-01, -6.8097e-01,\n",
       "          -1.6044e-01,  3.4499e-01, -3.8229e-01,  4.8806e-01, -8.1938e-01,\n",
       "          -3.2323e-01, -6.8975e-01, -4.3120e-01,  7.3553e-01,  8.9796e-01,\n",
       "          -1.0428e-01, -3.9348e-01, -6.5588e-01,  6.3766e-01, -9.0352e-01,\n",
       "           4.1658e-01,  5.6867e-01, -9.6661e-01, -9.8626e-01,  2.0883e-02,\n",
       "          -1.5976e-01,  2.1741e-01, -3.8847e-01, -8.2527e-01,  2.3344e-01,\n",
       "           4.7381e-01, -4.0818e-01, -6.1965e-02,  9.7325e-02, -6.5776e-01,\n",
       "          -3.4670e-01,  7.9799e-02, -5.5697e-01, -7.3260e-01, -2.2359e-02,\n",
       "          -5.3407e-01,  7.3371e-01,  7.3327e-01,  7.1427e-01, -4.9532e-01,\n",
       "           7.8406e-01,  2.5086e-01, -4.3917e-02,  6.5512e-02,  5.2642e-01,\n",
       "          -2.7105e-01,  1.3054e-01,  5.5375e-01,  4.1288e-01,  8.2844e-01,\n",
       "           2.9120e-01, -1.6284e-01,  1.8582e-01, -1.0056e-01,  4.6607e-01,\n",
       "           3.5127e-01, -3.6924e-01, -6.6026e-01,  9.0199e-01,  4.8383e-01,\n",
       "           1.1351e-01, -5.4637e-01, -9.2645e-01,  1.7305e-01, -5.9245e-01,\n",
       "           2.1925e-01, -1.7780e-01, -9.5735e-01, -1.7919e-01,  6.1984e-01,\n",
       "          -5.0473e-01, -5.8606e-01, -8.0632e-02,  6.4087e-01, -2.1436e-01,\n",
       "           9.6548e-01,  6.1861e-01,  1.3892e-01, -5.5841e-01,  2.1694e-01,\n",
       "           2.9599e-01, -9.1716e-01, -4.3544e-01, -2.7032e-01,  3.8949e-01,\n",
       "          -9.2906e-01, -8.2945e-01,  1.7194e-01, -4.0724e-01,  3.1348e-01,\n",
       "           3.8673e-01,  9.5344e-01, -7.9103e-01, -4.7172e-01,  4.6104e-01]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = walk(polytope=hypercube,\n",
    "        X0 = x0,  \n",
    "        z=100, \n",
    "        T=1, \n",
    "        warm=0,\n",
    "        thinning=10000, \n",
    "        device= None, \n",
    "        seed=None,\n",
    "        verbosity=2\n",
    ")\n",
    "X"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
