{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MHAR walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "\n",
    "from typing import  Union\n",
    "\n",
    "\n",
    "from mhar.polytope import Polytope, NFDPolytope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def sample_inner_points(X0, z):\n",
    "    n, k = X0.shape\n",
    "    if z > k:\n",
    "        # Pad by repeating vectors from X to fill z columns\n",
    "        num_repeats = z // k\n",
    "        remainder = z % k\n",
    "        I = torch.cat([X0] * num_repeats + [X0[:, :remainder]], dim=1)\n",
    "    elif z < k:\n",
    "        # Take the first z columns from X\n",
    "        I = X0[:, :z]\n",
    "    else:\n",
    "        # z == k, I equals X\n",
    "        I = X0.clone()\n",
    "    return I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_h(n,z,generator,dtype,device):\n",
    "    \"\"\"\n",
    "    Creates a Tensor (z x n x 1) where each entry ~ N(0,1). Automatically detects the\n",
    "    precision 64 bits or 32 bits.\n",
    "    -------------\n",
    "    :param n:   int\n",
    "                Dimension of the Space where the Polytope Lives\n",
    "    :param z:   int\n",
    "                Padding Parameter\n",
    "    :param generator:\n",
    "    :param device:  String, default = cpu\n",
    "                    Hardware used to make the computations and allocate the result.\n",
    "                    If equal to cpu then the CPUs are used for computing the inverse.\n",
    "                    If equal to cuda then the a GPU is used for computing the inverse.\n",
    "    -------------\n",
    "    :return:    Torch Tensor\n",
    "                Tensor (z x n x 1) where each entry ~ N(0,1)Contains a tensor\n",
    "\n",
    "    \"\"\"\n",
    "    if '64' in str(dtype):\n",
    "        if 'cuda' == device:\n",
    "            h = torch.cuda.DoubleTensor(z, n, 1).normal_(generator=generator)\n",
    "        elif 'cpu' == device:\n",
    "            h = torch.DoubleTensor(z, n, 1).normal_(generator=generator)\n",
    "    elif '32' in str(dtype):\n",
    "        if 'cuda' == device:\n",
    "            h = torch.cuda.FloatTensor(z, n, 1).normal_(generator=generator)\n",
    "        elif 'cpu' == device:\n",
    "            h = torch.FloatTensor(z, n, 1).normal_(generator=generator)\n",
    "    elif '16' in str(dtype):\n",
    "        if 'cuda' == device:\n",
    "            h = torch.cuda.HalfTensor(z, n, 1).normal_(generator=generator)\n",
    "        elif 'cpu' == device:\n",
    "            h = torch.HalfTensor(z, n, 1).normal_(generator=generator)\n",
    "\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_uniform(z, generator,dtype,device='cpu'):\n",
    "    \"\"\"\n",
    "    Creates a tensor (z x 1) where each entry ~ U(0,1). Automatically detects the\n",
    "    precision 64 bits or 32 bits.\n",
    "    -------------\n",
    "    :param n:   int\n",
    "                Dimension of the Space where the Polytope Lives\n",
    "    :param z:   int\n",
    "                Padding Parameter\n",
    "    :param generator:\n",
    "    :param device:  String, default = cpu\n",
    "                    Hardware used to make the computations and allocate the result.\n",
    "                    If equal to cpu then the CPUs are used for computing the inverse.\n",
    "                    If equal to cuda then the a GPU is used for computing the inverse.\n",
    "    -------------\n",
    "    :return:    Torch Tensor\n",
    "                Tensor (z x 1) where each entry ~ U(0,1)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if '64' in str(dtype):\n",
    "        if 'cuda' == device:\n",
    "            u = torch.cuda.DoubleTensor(z, 1).uniform_(generator=generator)\n",
    "        elif 'cpu' == device:\n",
    "            u = torch.DoubleTensor(z, 1).uniform_(generator=generator)\n",
    "    elif '32' in str(dtype):\n",
    "        if 'cuda' == device:\n",
    "            u = torch.cuda.FloatTensor(z, 1).uniform_(generator=generator)\n",
    "        elif 'cpu' == device:\n",
    "            u = torch.FloatTensor(z, 1).uniform_(generator=generator)\n",
    "    elif '16' in str(dtype):\n",
    "        if 'cuda' == device:\n",
    "            u = torch.cuda.HalfTensor(z, 1).uniform_(generator=generator)\n",
    "        elif 'cpu' == device:\n",
    "            u = torch.HalfTensor(z, 1).uniform_(generator=generator)\n",
    "\n",
    "    return u\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def walk(\n",
    "        polytope:Union[Polytope, NFDPolytope], # Polytope Object\n",
    "        X0:torch.Tensor,    # Initial Interior point(s) of dim=(n,k).     \n",
    "                            #- If z > k (number of columns in X0), pad  by repeating vectors from X to fill z columns.\n",
    "                            #- If z < k, take the first z columns from X0.\n",
    "                            #- If z == k, equal to X0.\n",
    "        z:int=1, # The number of simultaneous to be executed (padding parameter).\n",
    "        T:int=1, # id-iterations, total_iid_points = T*z. Each iid iteration will burn the samples established by the thinning factor.\n",
    "        warm:int=0, # Number of iid-iterations needed to warm. The walk will execute warm steps before saving the points.\n",
    "        thinning:int=None, # Thinning Factor. Default O(n^3)\n",
    "        device:str = 'cpu', # Deveice to use, cpu or cuda\n",
    "        seed:int=None, # Seed for Pseudo-Random Number Generation\n",
    "        verbosity:int=1, # Verbosity of the execution\n",
    "        ) -> None:\n",
    "        \n",
    "    ## Check validity \n",
    "    # Device\n",
    "    assert(device in ['cpu', 'cuda']), print('The device is not correctly specified: ', device,\n",
    "                                        '\\n Please choose cpu or cuda')\n",
    "    # X0 dimension\n",
    "    assert(X0.shape[0] == polytope.n)\n",
    "    \n",
    "    ## Set min and max values\n",
    "    min_ = torch.finfo(polytope.dtype).min + 2.0\n",
    "    max_ = torch.finfo(polytope.dtype).max - 2.0\n",
    "    if verbosity > 1:\n",
    "        print(f'Minimum number allowed {min_}')\n",
    "        print(f'Maximum number allowed {max_}')\n",
    "    \n",
    "    \n",
    "    ## Set seed\n",
    "    random_gen = torch.Generator(device=device)\n",
    "    if seed:\n",
    "        random_gen.manual_seed(seed)\n",
    "    else:\n",
    "        random_gen.seed()\n",
    "    \n",
    "    \n",
    "    ## Check Dimensions\n",
    "    n = polytope.n\n",
    "    mI = polytope.mI\n",
    "    if isinstance(polytope, NFDPolytope) :\n",
    "        mE = polytope.mE\n",
    "    else:\n",
    "        mE=None            \n",
    "    if verbosity >=1:\n",
    "        print('n: ', n, '  mI:', mI, '  mE:', mE, '  z:', z)\n",
    "        \n",
    "    \n",
    "    ## Compute/set thinning factor\n",
    "    if thinning:\n",
    "        pass\n",
    "    else:\n",
    "        thinning = int(n * n * n)\n",
    "        if verbosity >= 1:\n",
    "            print('Automatic Thinning factor: ', thinning)\n",
    "     \n",
    "            \n",
    "    ## Prepare and send Matrices\n",
    "    init_x0 = sample_inner_points(X0,z).to(device)  \n",
    "    polytope.send_to_device(device)\n",
    "    \n",
    "    \n",
    "    ## Iteration Loop\n",
    "    t = 1\n",
    "    burned = 0\n",
    "    dtype = polytope.dtype\n",
    "    while t <= T:\n",
    "        h = create_h(n, z, generator=random_gen, dtype=dtype,device=device)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
